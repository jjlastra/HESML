# Description:
#
# This script loads a collection of benchmarks among the
# UMLS::Similarity [1], SML [2] and HESML [3,4] semantic
# measures libraries. We compute the average speed and
# some Pearson and Spearman correlation metrics reportd in
# paper [4].
#
# References:
#
# [1] B.T. McInnes, T. Pedersen, S.V.S. Pakhomov,
# UMLS-Interface and UMLS-Similarity : open source software for
# measuring paths and semantic similarity, in: Proc. of the Annual
# Symposium of the American Medical Informatics Association,
# ncbi.nlm.nih.gov, San Francisco, CA, 2009: pp. 431–435.
# [2] S. Harispe, S. Ranwez, S. Janaqi, J. Montmain,
# The semantic measures library and toolkit: fast computation
# of semantic similarity and relatedness using biomedical ontologies,
# Bioinformatics. 30 (2014) 740–742.
# [3] J.J. Lastra-Díaz, A. García-Serrano, M. Batet, M. Fernández, F. Chirigati,
# HESML: a scalable ontology-based semantic similarity measures library with
# a set of reproducible experiments and a replication dataset,
# Information Systems. 66 (2017) 97–118.
# [4] J.J. Lastra-Díaz, A. Lara-Clares, A. García-Serrano,
# HESML: a real-time semantic measures library for the biomedical
# domain with a reproducible survey, Submitted for Publication. (2020).
# ----------

# We clear all session variables

rm(list = ls())

# IMPORTANT:configuration of the input/output directories
# We define below the input directory for the input raw results
# in CSV file format, and the output directory for the
# final assembled tables in CSV file format.
# You must change these values in order to
# point to the proper directories in your hard drive.
# We also define below the name of the input raw CSV files
# containing the experimental results.

# The input and output directories below must end with '/' in
# Unix-like format to be compatible with Windows
# or Linux-based R distributions.

# First, we get the current file script directory

current_working_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)

# and we set the working directory for the R project

setwd(current_working_dir)

# We set the input and output directories

rootDir = "../HESMLV1R5_paper/RawOutputFiles/"
inputDir = rootDir
outputDir = "../HESMLV1R5_paper/ProcessedOutputFiles/"

# ------------------------------------------------------------------------
# Table 6 (in the paper), Experiment 1 in HESML_UMLS_benchmark.java: Average speed in concepts per second in the SNOMED-CT ontology
# ------------------------------------------------------------------------

caption_table6 = "Average speed in CUI concept pairs per second for the evaluation of random CUI pairs with three representative ontology-based similarity measures based on the SNOMED-CT US 2019AB ontology (357406 nodes) implemented by the three UMLS-based semantic measures libraries reported in the literature. Best performing values are shown in bold. Non-implemented methods (---) or more than 1 hour/pair (xxx). UMLS::Similarity uses caching for the shortest path computations. \\hl{The number of random CUI pairs evaluated to measure each value is shown between parentheses.}"

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_Rada_SNOMEDCT_US <- read.csv(paste(inputDir, sep = "", "raw_output_Rada_SNOMEDCT_US.csv"), dec = ".", sep = ';')
rawdata_AncSPLRada_SNOMEDCT_US <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_SNOMEDCT_US.csv"), dec = ".", sep = ';')
rawdata_Lin_SNOMEDCT_US <- read.csv(paste(inputDir, sep = "", "raw_output_Lin_SNOMEDCT_US.csv"), dec = ".", sep = ';')
rawdata_WuPalmer_SNOMEDCT_US <- read.csv(paste(inputDir, sep = "", "raw_output_WuPalmerFast_SNOMEDCT_US.csv"), dec = ".", sep = ';')

# We create the table 1 as reported in the paper [4]

table6 <- matrix(nrow = 4, ncol = 4);

colnames(table6) <- c("Similarity measure", "UMLS::Sim", "SML", "HESML");

# We fill the row reporting the evaluation of the Rada measure

table6[1,1] = "Rada";
# table6[1,2] = "edge-counting";
table6[1,2] = round(rawdata_Rada_SNOMEDCT_US[1,2] / mean(rawdata_Rada_SNOMEDCT_US[2:6,3]), digits = 3)
table6[1,3] = "xxx";
table6[1,4] = round(rawdata_Rada_SNOMEDCT_US[1,4] / mean(rawdata_Rada_SNOMEDCT_US[2:6,5]), digits = 3)

table6[2,1] = "AnsSPLRada";
# table6[2,2] = "edge-counting";
table6[2,2] = "---";
table6[2,3] = "---";
table6[2,4] = round(rawdata_AncSPLRada_SNOMEDCT_US[1,4] / mean(rawdata_AncSPLRada_SNOMEDCT_US[2:6,5]), digits = 3)

table6[3,1] = "Lin";
# table6[3,2] = "IC-based";
table6[3,2] = round(rawdata_Lin_SNOMEDCT_US[1,2] / mean(rawdata_Lin_SNOMEDCT_US[2:6,3]), digits = 3)
table6[3,3] = round(rawdata_Lin_SNOMEDCT_US[1,6] / mean(rawdata_Lin_SNOMEDCT_US[2:6,7]), digits = 3)
table6[3,4] = round(rawdata_Lin_SNOMEDCT_US[1,4] / mean(rawdata_Lin_SNOMEDCT_US[2:6,5]), digits = 3)

table6[4,1] = "Wu-Palmer_fast";
# table6[4,2] = "depth-based";
table6[4,2] = round(rawdata_WuPalmer_SNOMEDCT_US[1,2] / mean(rawdata_WuPalmer_SNOMEDCT_US[2:6,3]), digits = 3)
table6[4,3] = "---";
table6[4,4] = round(rawdata_WuPalmer_SNOMEDCT_US[1,4] / mean(rawdata_WuPalmer_SNOMEDCT_US[2:6,5]), digits = 3)

# ------------------------------------------------------------------------
# Table 7 (in the paper), Experiment 2 in HESML_UMLS_benchmark.java: Average speed in concepts per second in the MeSH ontology
# ------------------------------------------------------------------------

caption_table7 = "Average speed in CUI concept pairs per second for the evaluation of random CUI pairs with three representative ontology-based similarity measures based on the MeSH ontology (Nov, 2019. 59747 nodes) implemented by the three UMLS-based semantic measures libraries reported in the literature. Best performing values are shown in bold. Non-implemented methods (---). \\hl{The number of random CUI pairs evaluated to measure each value is shown between parentheses.}"

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_Rada_MeSH <- read.csv(paste(inputDir, sep = "", "raw_output_Rada_MeSH.csv"), dec = ".", sep = ';')
rawdata_AncSPLRada_MeSH <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_MeSH.csv"), dec = ".", sep = ';')
rawdata_Lin_MeSH <- read.csv(paste(inputDir, sep = "", "raw_output_Lin_MeSH.csv"), dec = ".", sep = ';')
rawdata_WuPalmer_MeSH <- read.csv(paste(inputDir, sep = "", "raw_output_WuPalmerFast_MeSH.csv"), dec = ".", sep = ';')

# We create the table 2 as reported in the paper [4]

table7 <- matrix(nrow = 4, ncol = 5);

colnames(table7) <- c("Similarity measure", "Measure type", "UMLS::Sim", "SML", "HESML");

# We fill the row reporting the evaluation of the Rada measure

table7[1,1] = "Rada";
table7[1,2] = "edge-counting";
table7[1,3] = round(rawdata_Rada_MeSH[1,2] / mean(rawdata_Rada_MeSH[2:6,3]), digits = 3)
table7[1,4] = round(rawdata_Rada_MeSH[1,6] / mean(rawdata_Rada_MeSH[2:6,7]), digits = 3)
table7[1,5] = round(rawdata_Rada_MeSH[1,4] / mean(rawdata_Rada_MeSH[2:6,5]), digits = 3)

table7[2,1] = "AnsSPLRada";
table7[2,2] = "edge-counting";
table7[2,3] = "---";
table7[2,4] = "---";
table7[2,5] = round(rawdata_AncSPLRada_MeSH[1,4] / mean(rawdata_AncSPLRada_MeSH[2:6,5]), digits = 3)

table7[3,1] = "Lin";
table7[3,2] = "IC-based";
table7[3,3] = round(rawdata_Lin_MeSH[1,2] / mean(rawdata_Lin_MeSH[2:6,3]), digits = 3)
table7[3,4] = round(rawdata_Lin_MeSH[1,6] / mean(rawdata_Lin_MeSH[2:6,7]), digits = 3)
table7[3,5] = round(rawdata_Lin_MeSH[1,4] / mean(rawdata_Lin_MeSH[2:6,5]), digits = 3)

table7[4,1] = "Wu-Palmer_fast";
table7[4,2] = "depth-based";
table7[4,3] = round(rawdata_WuPalmer_MeSH[1,2] / mean(rawdata_WuPalmer_MeSH[2:6,3]), digits = 3)
table7[4,4] = "---";
table7[4,5] = round(rawdata_WuPalmer_MeSH[1,4] / mean(rawdata_WuPalmer_MeSH[2:6,5]), digits = 3)

# ------------------------------------------------------------------------
# Table 8 (in the paper), Experiment 3 in HESML_UMLS_benchmark.java: Average speed in GO concept pairs per second for the evaluation 
# of two representative ontology-based similarity measures based on the Gene Ontology
#
# ------------------------------------------------------------------------

caption_table8 = "Average speed in GO concept pairs per second for the evaluation of two representative ontology-based similarity measures based on the Gene Ontology \\cite{Ashburner2000-nu, The_Gene_Ontology_Consortium2019-hp} (2020-05-02 version) implemented by state-of-the-art SML \\cite{Harispe2014-cw} library and HESML. Best performing values are shown in bold.  \\hl{The number of random GO concept pairs evaluated to measure each value is shown between parentheses.}"

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_Rada_GO <- read.csv(paste(inputDir, sep = "", "raw_output_Rada_GO.csv"), dec = ".", sep = ';')
rawdata_AncSPLRada_GO <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_GO.csv"), dec = ".", sep = ';')
rawdata_Lin_GO <- read.csv(paste(inputDir, sep = "", "raw_output_Lin_GO.csv"), dec = ".", sep = ';')

# We create the table 1 as reported in the paper [4]

table8 <- matrix(nrow = 3, ncol = 4);

colnames(table8) <- c("Similarity measure", "Measure type", "SML", "HESML");

# We fill the row reporting the evaluation of the Rada measure

table8[1,1] = "Rada";
table8[1,2] = "edge-counting";
table8[1,3] = round(rawdata_Rada_GO[1,2] / mean(rawdata_Rada_GO[2:6,3]), digits = 3)
table8[1,4] = round(rawdata_Rada_GO[1,4] / mean(rawdata_Rada_GO[2:6,5]), digits = 3)

table8[2,1] = "AnsSPLRada";
table8[2,2] = "edge-counting";
table8[2,3] = "---";
table8[2,4] = round(rawdata_AncSPLRada_GO[1,4] / mean(rawdata_AncSPLRada_GO[2:6,5]), digits = 3)

table8[3,1] = "Lin";
table8[3,2] = "IC-based";
table8[3,3] = round(rawdata_Lin_GO[1,2] / mean(rawdata_Lin_GO[2:6,3]), digits = 3)
table8[3,4] = round(rawdata_Lin_GO[1,4] / mean(rawdata_Lin_GO[2:6,5]), digits = 3)


# ------------------------------------------------------------------------
# Table 9 (in the paper), Experiment 7 in HESML_UMLS_benchmark.java: Average speed in the evaluation of the semantic simialirity
# between sentence pairs of the MedSTS [1] dataset with the the MeSH
# ontology and a collection of 1M of sentence pairs from the BioC corpus.
#
# [1] Y. Wang, N. Afzal, S. Fu, L. Wang, F. Shen, M. Rastegar-Mojarad, H. Liu,
# MedSTS: a resource for clinical semantic textual similarity,
# Language Resources and Evaluation. (2018) 1–16.
# ------------------------------------------------------------------------

caption_table9 = "Average speed in sentence pairs per second \\hl{(sent/secs) and CUI pairs per second (CUIs/secs)} for the evaluation of the UBSM \\cite{Sogancioglu2017-kb} sentence similarity measure combined with three representative ontology-based similarity measures based on MeSH (Nov, 2019) in \\hl{30} sentence pairs \\hl{extracted from} the MedSTS \\cite{Wang2018-oj} sentence similarity dataset, \\hl{and 1 million sentence pairs extracted from BioC corpus} \\cite{Comeau2019-ex}\\hl{. We provide the average evaluation in normalized CUI pairs per second to allow a fair and unbiased comparison of the results reported for 30 and 1 million sentence pairs. The dataset with 30 sentence pairs requires XXXX pairwise CUI comparisons, whilst the 1 million sentence pairs dataset requires YYY pairwise CUI comparisons.} Best performing values are shown in bold. Non-implemented methods (---)."

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_Rada_MedSTS <- read.csv(paste(inputDir, sep = "", "raw_output_Rada_MedSTS.csv"), dec = ".", sep = ';')
rawdata_AncSPLRada_MedSTS <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_MedSTS.csv"), dec = ".", sep = ';')
rawdata_Lin_MedSTS <- read.csv(paste(inputDir, sep = "", "raw_output_Lin_MedSTS.csv"), dec = ".", sep = ';')
rawdata_WuPalmer_MedSTS <- read.csv(paste(inputDir, sep = "", "raw_output_WuPalmerFast_MedSTS.csv"), dec = ".", sep = ';')

# We create the table 4 as reported in the paper [4]

table9 <- matrix(nrow = 5, ncol = 5);

colnames(table9) <- c("Similarity measure", "Measure type", "UMLS::Sim", "SML", "HESML");

# SML library uses caching to store the similarity values. For this reason,
# we only consider the first value for a fair comparison.

# We fill the row reporting the evaluation of the Rada measure

table9[1,1] = "Rada";
table9[1,2] = "edge-counting";
table9[1,3] = round(rawdata_Rada_MedSTS[6,2] / mean(rawdata_Rada_MedSTS[1:5,2]), digits = 3)
table9[1,4] = round(rawdata_Rada_MedSTS[6,3] / mean(rawdata_Rada_MedSTS[1,3]), digits = 3)
table9[1,5] = round(rawdata_Rada_MedSTS[6,4] / mean(rawdata_Rada_MedSTS[1:5,4]), digits = 3)
table9[1,6] = round(rawdata_Rada_MedSTS[6,5] / mean(rawdata_Rada_MedSTS[1:5,5]), digits = 3)

table9[2,1] = "AnsSPLRada";
table9[2,2] = "edge-counting";
table9[2,3] = "---";
table9[2,4] = "---";
table9[2,5] = round(rawdata_AncSPLRada_MedSTS[6,4] / mean(rawdata_AncSPLRada_MedSTS[1:5,4]), digits = 3)
table9[2,5] = round(rawdata_AncSPLRada_MedSTS[6,5] / mean(rawdata_AncSPLRada_MedSTS[1:5,5]), digits = 3)

table9[3,1] = "Lin";
table9[3,2] = "IC-based";
table9[3,3] = round(rawdata_Lin_MedSTS[6,2] / mean(rawdata_Lin_MedSTS[1:5,2]), digits = 3)
table9[3,4] = round(rawdata_Lin_MedSTS[6,3] / mean(rawdata_Lin_MedSTS[1:5,3]), digits = 3)
table9[3,5] = round(rawdata_Lin_MedSTS[6,4] / mean(rawdata_Lin_MedSTS[1:5,4]), digits = 3)
table9[3,6] = round(rawdata_Lin_MedSTS[6,5] / mean(rawdata_Lin_MedSTS[1:5,5]), digits = 3)

table9[4,1] = "Wu-Palmer_fast";
table9[4,2] = "depth-based";
table9[4,3] = round(rawdata_WuPalmer_MedSTS[6,2] / mean(rawdata_WuPalmer_MedSTS[1:5,2]), digits = 3)
table9[4,4] = "---";
table9[4,5] = round(rawdata_WuPalmer_MedSTS[6,4] / mean(rawdata_WuPalmer_MedSTS[1:5,4]), digits = 3)
table9[4,6] = round(rawdata_WuPalmer_MedSTS[6,5] / mean(rawdata_WuPalmer_MedSTS[1:5,5]), digits = 3)

table9[5,1] = "Total CUI comparisons";
table9[5,2] = rawdata_Rada_MedSTS[7,2];
table9[5,3] = rawdata_AncSPLRada_MedSTS[7,2];
table9[5,4] = rawdata_Lin_MedSTS[7,2];
table9[5,5] = rawdata_WuPalmer_MedSTS[7,2];


# ------------------------------------------------------------------------
# Table 10 (in the paper), Experiment 4 in HESML_UMLS_benchmark.java: Pearson and Spearman correlation between base path-based measures
# and their AncSPL variant
# ------------------------------------------------------------------------


caption_table10 = "This table shows the Pearson \\hl{(r)} and Spearman \\hl{($\\rho$)} correlation values between the similarity values returned by a set of path-based similarity measures and those values returned by their reformulation based on the new AncSPL algorithm \\hl{for a sequence of 1000} random CUI pairs in SNOMED-CT 2019AB. \\hl{We show the results obtained in the evaluation of the first 50, 100, 200, and 1000 random CUI pairs}. All similarity measures are implemented in HESML V1R5 \\cite{Lastra-Diaz2020-xv}. CoswJ\\&C \\cite{Lastra-Diaz2015-ct} sets the current state-of-the-art in the family of ontology-based semantic similarity measures based on WordNet \\cite{Lastra-Diaz2019-kg}. \\hl{Note: the evaluation of any AncSPL-based measure in any tree-like taxonomy as MeSH will always report Pearson, and Spearman correlation metrics equal to 1, regardless of the number of CUI pairs, because AncSPL is exact in this case}."

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_AncSPLRada_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_exp4.csv"), dec = ".", sep = ';')
rawdata_AncSPLLeacock_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLLeacockChodorow_exp4.csv"), dec = ".", sep = ';')
rawdata_AncSPLCosine_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLCosineNormWeightedJiangConrath_exp4.csv"), dec = ".", sep = ';')

# We create the table 5 as reported in the paper [4]

table10 <- matrix(nrow = 3, ncol = 10);

colnames(table10) <- c("Base measure", "AncSPL reformulation", "Pearson", "Spearman", "Pearson", "Spearman", "Pearson", "Spearman", "Pearson", "Spearman");

# We select the number of random rows to be used for each range of results

n_samples_1 <- 50
n_samples_2 <- 100
n_samples_3 <- 200
n_samples_4 <- 1000

# We select the sample tables for each part of the experiment 4

rawdata_AncSPLRada_exp4_sample_rows_1 <- head(rawdata_AncSPLRada_exp4,n_samples_1)
rawdata_AncSPLRada_exp4_sample_rows_2 <- head(rawdata_AncSPLRada_exp4,n_samples_2)
rawdata_AncSPLRada_exp4_sample_rows_3 <- head(rawdata_AncSPLRada_exp4,n_samples_3)
rawdata_AncSPLRada_exp4_sample_rows_4 <- head(rawdata_AncSPLRada_exp4,n_samples_4)

rawdata_AncSPLLeacock_exp4_sample_rows_1 <- head(rawdata_AncSPLLeacock_exp4,n_samples_1)
rawdata_AncSPLLeacock_exp4_sample_rows_2 <- head(rawdata_AncSPLLeacock_exp4,n_samples_2)
rawdata_AncSPLLeacock_exp4_sample_rows_3 <- head(rawdata_AncSPLLeacock_exp4,n_samples_3)
rawdata_AncSPLLeacock_exp4_sample_rows_4 <- head(rawdata_AncSPLLeacock_exp4,n_samples_4)

rawdata_AncSPLCosine_exp4_sample_rows_1 <- head(rawdata_AncSPLCosine_exp4,n_samples_1)
rawdata_AncSPLCosine_exp4_sample_rows_2 <- head(rawdata_AncSPLCosine_exp4,n_samples_2)
rawdata_AncSPLCosine_exp4_sample_rows_3 <- head(rawdata_AncSPLCosine_exp4,n_samples_3)
rawdata_AncSPLCosine_exp4_sample_rows_4 <- head(rawdata_AncSPLCosine_exp4,n_samples_4)

# We fill the row reporting the evaluation of the Rada measure

table10[1,1] = "Rada";
table10[1,2] = "AnsSPL-Rada";
table10[1,3] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_1[,3], rawdata_AncSPLRada_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table10[1,4] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_1[,3], rawdata_AncSPLRada_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table10[1,5] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_2[,3], rawdata_AncSPLRada_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table10[1,6] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_2[,3], rawdata_AncSPLRada_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table10[1,7] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_3[,3], rawdata_AncSPLRada_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table10[1,8] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_3[,3], rawdata_AncSPLRada_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table10[1,9] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_4[,3], rawdata_AncSPLRada_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table10[1,10] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_4[,3], rawdata_AncSPLRada_exp4_sample_rows_4[, 4], method = "spearman"), 4)

table10[2,1] = "Leacock-Chodorow";
table10[2,2] = "AnsSPL-Leacock";
table10[2,3] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_1[,3], rawdata_AncSPLLeacock_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table10[2,4] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_1[,3], rawdata_AncSPLLeacock_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table10[2,5] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_2[,3], rawdata_AncSPLLeacock_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table10[2,6] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_2[,3], rawdata_AncSPLLeacock_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table10[2,7] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_3[,3], rawdata_AncSPLLeacock_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table10[2,8] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_3[,3], rawdata_AncSPLLeacock_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table10[2,9] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_4[,3], rawdata_AncSPLLeacock_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table10[2,10] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_4[,3], rawdata_AncSPLLeacock_exp4_sample_rows_4[, 4], method = "spearman"), 4)

table10[3,1] = "coswJ&C";
table10[3,2] = "AnsSPL-coswJ&C";
table10[3,3] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_1[,3], rawdata_AncSPLCosine_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table10[3,4] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_1[,3], rawdata_AncSPLCosine_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table10[3,5] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_2[,3], rawdata_AncSPLCosine_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table10[3,6] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_2[,3], rawdata_AncSPLCosine_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table10[3,7] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_3[,3], rawdata_AncSPLCosine_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table10[3,8] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_3[,3], rawdata_AncSPLCosine_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table10[3,9] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_4[,3], rawdata_AncSPLCosine_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table10[3,10] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_4[,3], rawdata_AncSPLCosine_exp4_sample_rows_4[, 4], method = "spearman"), 4)

# ------------------------------------------------------------
# We save all final data tables 
# ------------------------------------------------------------

write.csv(table6, file = paste(outputDir, sep="","table6.csv"))
write.csv(table7, file = paste(outputDir, sep="","table7.csv"))
write.csv(table8, file = paste(outputDir, sep="","table8.csv"))
write.csv(table9, file = paste(outputDir, sep="","table9.csv"))
write.csv(table10, file = paste(outputDir, sep="","table10.csv"))

#-------------------------------
# HTML report generation
#-------------------------------

library(knitr)
library(readr)

# We load and browse Table 6 in the paper

kable_out <- kable(table6,
                   caption = caption_table6,
                   format = "html")

readr::write_file(kable_out, paste(outputDir, sep="","Table6.html"))
# browseURL(paste(outputDir, sep="","Table6.html"))

# We load and browse Table 7 in the paper

kable_out <- kable(table7,
                   caption = caption_table7,
                   format = "html")

readr::write_file(kable_out, paste(outputDir, sep="","Table7.html"))
# browseURL(paste(outputDir, sep="","Table7.html"))

# We load and browse Table 8 in the paper

kable_out <- kable(table8,
                   caption = caption_table8,
                   format = "html")

readr::write_file(kable_out, paste(outputDir, sep="","Table8.html"))
# browseURL(paste(outputDir, sep="","Table8.html"))

# We load and browse Table 9 in the paper

kable_out <- kable(table9,
                   caption = caption_table9,
                   format = "html")

readr::write_file(kable_out, paste(outputDir, sep="","Table9.html"))
# browseURL(paste(outputDir, sep="","Table9.html"))

# We load and browse Table 10 in the paper

kable_out <- kable(table10,
                   caption = caption_table10,
                   format = "html")

readr::write_file(kable_out, paste(outputDir, sep="","Table10.html"))
# browseURL(paste(outputDir, sep="","Table10.html"))


#############################
# we export the latex tables
#############################

library(knitr)
library(readr)
library(kableExtra)
library(stringr)
library(xtable)






#############################
# Table 6
#############################

# We define the latex table with the data

colnames(table6) <- c("Similarity measure", 
                      "\\makecell[c]{\\underline{UMLS::Sim} \\\\ Avg. speed \\\\ (pairs/sec)}", 
                      "\\makecell[c]{\\underline{SML} \\\\ Avg. speed \\\\ (pairs/sec)}", 
                      "\\makecell[c]{\\underline{HESML} \\\\ Avg. speed \\\\ (pairs/sec)}");

# Format the table modifying the fields

table6[1,1] = "Rada \\cite{Rada1989-cv}";
table6[2,1] = "\\makecell[l]{AncSPL-Rada \\\\ (this work)}";
table6[3,1] = "Lin-Seco \\cite{Lin1998-pm, Seco2004-fd}";
table6[4,1] = "Wu-Palmer$_{fast}$ \\cite{Wu1994-hh}";

table6[1,2] = paste0("\\hl{\\textbf{",table6[1,2],"}} (",rawdata_Rada_SNOMEDCT_US[1,2],")")
table6[1,4] = paste0("\\hl{",table6[1,4],"} (",rawdata_Rada_SNOMEDCT_US[1,4],")")

table6[2,4] = paste0("\\hl{\\textbf{",round(as.numeric(table6[2,4],decimal=0)),"}}",str_replace(rawdata_AncSPLRada_SNOMEDCT_US[1,4],"1000000","$(10^6)$"))

table6[3,2] = paste0("\\hl{",table6[3,2],"} (",rawdata_Lin_SNOMEDCT_US[1,2],")")
table6[3,3] = paste0("\\hl{",round(as.numeric(table6[3,3],decimal=0)),"}",str_replace(rawdata_Lin_SNOMEDCT_US[1,6],"1000000","$(10^6)$"))
table6[3,4] = paste0("\\hl{\\textbf{",round(as.numeric(table6[3,4],decimal=0)),"}}",str_replace(rawdata_Lin_SNOMEDCT_US[1,4],"1000000","$(10^6)$"))

table6[4,2] = paste0("\\hl{\\textbf{",table6[4,2],"}} (",rawdata_WuPalmer_SNOMEDCT_US[1,2],")")
table6[4,4] = paste0("\\hl{\\textbf{",round(as.numeric(table6[4,4],decimal=0)),"}}",str_replace(rawdata_WuPalmer_SNOMEDCT_US[1,4],"1000000","$(10^6)$"))

table_latex <- xtable(table6, type = "latex", digits=4, method = "compact")

# We add extra rows to the table before printing it

addtorow      <- list()
addtorow$pos  <- list()

# We add an extra header with the dataset groups

addtorow$pos[[1]] <- -1
addtorow$command  <- c('')

# we define a function for adding \small to all rows. 

add_small_to_all_rows.allrows <- function(x) {
  x
}

# We align the table 

# align(table_latex) <- "lcp{1.5cm}p{1.4cm}p{1.4cm}"

# We save the tables in latex and HTML format files. The HTML format is for 

strLatexTables <- print(xtable(table_latex, caption = caption_table6, label = "tab:uno", digits=3, align ="llp{1.5cm}p{1.4cm}p{1.4cm}"), caption.placement = 'top',floating.environment = "table",
                        comment=FALSE, table.placement="h!", include.rownames=FALSE,
                        sanitize.colnames.function = identity, sanitize.text.function =  add_small_to_all_rows.allrows)




