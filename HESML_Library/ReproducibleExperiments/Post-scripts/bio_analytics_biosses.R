# Description:
#
# This script loads a collection of sentence similarity benchmarks generated
# by HESMLSTSclient program, which contain the raw similarity values for
# sentence pair. Then, the script create the tables for analyzing the results.
#

# We clear all session variables

rm(list = ls())

# We add the dplyr library

library(dplyr)

# Import the readr library

library(readr)

# IMPORTANT:configuration of the input/output directories
# We define below the input directory for the input raw results
# in CSV file format, and the output directory for the
# final assembled tables in CSV file format.
# You must change these values in order to
# point to the proper directories in your hard drive.
# We also define below the name of the input raw CSV files
# containing the experimental results.

# The input and output directories below must end with '/' in
# Unix-like format to be compatible with Windows
# or Linux-based R distributions.

# First, we get the current file script directory

current_working_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)

# and we set the working directory for the R project

setwd(current_working_dir)

# Define the root path 

rootDir = "../BioSentenceSimilarity_paper"

# We define the subdirectory experiment and the caption for showing the results in Latex and HTML format
# and we add to the dictionary all the String-based measures experiments

experimentSubdirectory = "BioSentenceSimFinalRawOutputFiles"
preprocessedExperimentsSubdirectory = "BioSentenceSimFinalProcessedOutputFiles"

# We define the output directory 

dir.create(paste(rootDir, "/", preprocessedExperimentsSubdirectory, "/", sep = ""))
outputDir =  paste(rootDir, "/", preprocessedExperimentsSubdirectory, "/", sep = "")

# Input raw CSV files generated by the reproducible experiments detailed
# in the companion paper for each sentence similarity dataset

# We define the input datasets directories

inputDir = paste(rootDir, "/", experimentSubdirectory, "/", sep = "")

# We load the input raw results file for best combinations (FINAL RESULTS)

source(paste("bio_sentence_sim_scripts", "readBESTCOMBS.R", sep = "/"), local = knitr::knit_global())

# First, we select all the measures, and we will only work with a dataset. 

rawdata_results_biosses <- na.omit(rawdata_BESTCOMBS[2][[1]])

# Now, we read the file which contains the sentences 

path_to_biosses_sentences_file <- "../../SentenceSimDatasets/BIOSSESNormalized.tsv"

# Use read_tsv() to read text file

sentences = read_tsv(path_to_biosses_sentences_file, col_names = FALSE)

#################################################
#################################################

# Pre-processing the data

#################################################
#################################################

# We add a column with the normalized Human scores to [0,1] using si = (xi – min(x)) / (max(x) – min(x))

# First, we get the max and min values

max_human <- max(rawdata_results_biosses$Human)
min_human <- min(rawdata_results_biosses$Human)

rawdata_results_biosses$HumanNormalized <- with(rawdata_results_biosses, (Human - min_human) / (max_human - min_human) )

# We add, for each measure, the value that represents the error: normalized_absolute_relative_error(i) = |score_measure(i) - score_human_norm(i)| / score_human_norm(i)

for (i in colnames(rawdata_results_biosses))
{
  # We do not parse the columns Human and HumanNormalize
  
  if(i != "Human" & i != "HumanNormalized")
  {
    # First, we calculate the error for each row and we set a generic column name "colname_i"
    
    rawdata_results_biosses$colname_i <- with(rawdata_results_biosses, abs(rawdata_results_biosses[[i]] - HumanNormalized))
    
    # Then, we set the new column name. For instance, "abs_relative_error_"
    
    names(rawdata_results_biosses)[names(rawdata_results_biosses) == 'colname_i'] <- paste("abs_relative_error_", i, sep="")
    
    # We create another column with no absolute values
    
    rawdata_results_biosses$colname_j <- with(rawdata_results_biosses, rawdata_results_biosses[[i]] - HumanNormalized)
    
    # Then, we set the new column name. For instance, "relative_error_"
    
    names(rawdata_results_biosses)[names(rawdata_results_biosses) == 'colname_j'] <- paste("rel_error_", i, sep="")
  }
}

# Now, we add a new column which represents the sum of the errors for each value sum_errors(i) = abs(SUM(score_error_measures))

# colnames(rawdata_results_biosses[grepl('abs_relative_error_', names(rawdata_results_biosses))])

rawdata_results_biosses$abs_sum_errors_all_methods <- rowSums(rawdata_results_biosses[grepl('abs_relative_error_', names(rawdata_results_biosses))])

# On the other hand, we will filter the columns and we will also compute the summatory of the relative error taking into account only the best-performing methods of each family

# colnames(rawdata_results_biosses)
# colnames(rawdata_results_biosses[c(63,85,91,113)])

rawdata_results_biosses$abs_sum_errors_best_methods <- rowSums(rawdata_results_biosses[c(63,85,91,113)])

# We reorder the table by the abs_sum_errors_all_methods or the abs_sum_errors_best_methods column

# rawdata_results_biosses <- rawdata_results_biosses[order(rawdata_results_biosses$abs_sum_errors_all_methods),]

# rawdata_results_biosses <- rawdata_results_biosses[order(rawdata_results_biosses$abs_sum_errors_best_methods),]

# Now, we will only work with the best-performing methods for each family, and the computed values

# colnames(rawdata_results_biosses)
# colnames(rawdata_results_biosses[c(1,52,7,18,21,32,63,64,85,86,91,92,113,114,153,154)])

rawdata_results_biosses_filtered <- rawdata_results_biosses[, c(1,52,7,18,21,32,63,64,85,86,91,92,113,114,153,154)]

# The selection of the sentences will take into account the accumulated errors for all methods

# We add the sentences to the list

rawdata_results_biosses_filtered$rawSentences <- sentences[, 1:2]

# We set the number of sentences we want to extract

n <- 4

# We select the last n rows, which corresponds to the rows with the max error value and we cast the list to numeric values

first_index_last <- nrow(rawdata_results_biosses_filtered)-n+1
last_index_last <- nrow(rawdata_results_biosses_filtered)

# Now, we have to select the best and worst sentences from the rawdata_results_biosses_filtered table

results_biosses_all_methods_lower_errors <- rawdata_results_biosses_filtered[1:n, ]
results_biosses_all_methods_higher_errors <- rawdata_results_biosses_filtered[first_index_last:last_index_last, ]

# The next step is to add the sentences to the tables for allowing the analysis of the results

# We select the first, mid and last n rows, which corresponds to the rows with the minimum, medium and max error values and we cast the list to numeric values

first_n_rows = as.numeric(unlist(rownames(rawdata_results_biosses_filtered[1:n, ])))
last_n_rows = as.numeric(unlist(rownames(rawdata_results_biosses_filtered[first_index_last:last_index_last, ])))

# We add the new columns with the raw sentences

results_biosses_all_methods_lower_errors$rawSentences <- sentences[first_n_rows, 1:2]
results_biosses_all_methods_higher_errors$rawSentences <- sentences[last_n_rows, 1:2]

# We save the results
write.csv2(rawdata_results_biosses_filtered, file = paste(outputDir,"rawdata_results_biosses_filtered.csv", sep=""))

write.csv2(results_biosses_all_methods_lower_errors, file = paste(outputDir,"results_biosses_all_methods_lower_errors.csv", sep=""))
write.csv2(results_biosses_all_methods_higher_errors, file = paste(outputDir,"results_biosses_all_methods_higher_errors.csv", sep=""))

results_biosses_all_methods_lower_errors$rawSentences

mean_liblock <- round(mean(rawdata_results_biosses_filtered$LiBlock), 3)
mean_WBSM_AncSPLRada <- round(mean(rawdata_results_biosses_filtered$WBSM_AncSPLRada), 3)
mean_bio_embedding_intrinsic <- round(mean(rawdata_results_biosses_filtered$bio_embedding_intrinsic), 3)
mean_oubiobert <- round(mean(rawdata_results_biosses_filtered$oubiobert.base.uncased_tok.wordpiecetokenizer_lc_sw.nonestopwords_cf.default_ner.none), 3)
mean_human <- round(mean(rawdata_results_biosses_filtered$HumanNormalized), 3)


mean_liblock
mean_WBSM_AncSPLRada
mean_bio_embedding_intrinsic
mean_oubiobert
mean_human

median_liblock <- round(median(rawdata_results_biosses_filtered$LiBlock), 3)
median_WBSM_AncSPLRada <- round(median(rawdata_results_biosses_filtered$WBSM_AncSPLRada), 3)
median_bio_embedding_intrinsic <- round(median(rawdata_results_biosses_filtered$bio_embedding_intrinsic), 3)
median_oubiobert <- round(median(rawdata_results_biosses_filtered$oubiobert.base.uncased_tok.wordpiecetokenizer_lc_sw.nonestopwords_cf.default_ner.none), 3)
median_human <- round(median(rawdata_results_biosses_filtered$HumanNormalized), 3)

median_liblock
median_WBSM_AncSPLRada
median_bio_embedding_intrinsic
median_oubiobert
median_human

sd_liblock <- round(sd(rawdata_results_biosses_filtered$LiBlock, TRUE), 3)
sd_WBSM_AncSPLRada <- round(sd(rawdata_results_biosses_filtered$WBSM_AncSPLRada, TRUE), 3)
sd_bio_embedding_intrinsic <- round(sd(rawdata_results_biosses_filtered$bio_embedding_intrinsic, TRUE), 3)
sd_oubiobert <- round(sd(rawdata_results_biosses_filtered$oubiobert.base.uncased_tok.wordpiecetokenizer_lc_sw.nonestopwords_cf.default_ner.none, TRUE), 3)
sd_human <- round(sd(rawdata_results_biosses_filtered$HumanNormalized, TRUE), 3)

sd_liblock
sd_WBSM_AncSPLRada
sd_bio_embedding_intrinsic
sd_oubiobert
sd_human

max_liblock <- round(max(rawdata_results_biosses_filtered$LiBlock), 3)
max_WBSM_AncSPLRada <- round(max(rawdata_results_biosses_filtered$WBSM_AncSPLRada), 3)
max_bio_embedding_intrinsic <- round(max(rawdata_results_biosses_filtered$bio_embedding_intrinsic), 3)
max_oubiobert <- round(max(rawdata_results_biosses_filtered$oubiobert.base.uncased_tok.wordpiecetokenizer_lc_sw.nonestopwords_cf.default_ner.none), 3)
max_human <- round(max(rawdata_results_biosses_filtered$HumanNormalized), 3)

max_liblock
max_WBSM_AncSPLRada
max_bio_embedding_intrinsic
max_oubiobert
max_human

min_liblock <- round(min(rawdata_results_biosses_filtered$LiBlock), 3)
min_WBSM_AncSPLRada <- round(min(rawdata_results_biosses_filtered$WBSM_AncSPLRada), 3)
min_bio_embedding_intrinsic <- round(min(rawdata_results_biosses_filtered$bio_embedding_intrinsic), 3)
min_oubiobert <- round(min(rawdata_results_biosses_filtered$oubiobert.base.uncased_tok.wordpiecetokenizer_lc_sw.nonestopwords_cf.default_ner.none), 3)
min_human <- round(min(rawdata_results_biosses_filtered$HumanNormalized), 3)

min_liblock
min_WBSM_AncSPLRada
min_bio_embedding_intrinsic
min_oubiobert
min_human

#################################################
#################################################

# Analytics stage

#################################################
#################################################

# We plot the histograms

# LiBlock <- hist(rawdata_results_biosses_filtered$rel_error_LiBlock)

# We test if the data has a normal distribution

library("dplyr")
library("ggpubr")

hist(rawdata_results_biosses_filtered$HumanNormalized)

# First, visually, using the Q-Q plot

rawdata_results_biosses_filtered$rel_error_LiBlock

ggqqplot(rawdata_results_biosses_filtered$rel_error_LiBlock)

# Second, we make the saphiro test

t <- shapiro.test(rawdata_results_biosses_filtered$rel_error_LiBlock)

is_normal_distribution = FALSE
if(t$p.value > 0.05)
  is_normal_distribution = TRUE

is_normal_distribution

mean_error_liblock <- round(mean(rawdata_results_biosses_filtered$rel_error_LiBlock), 3)
mean_error_WBSM_AncSPLRada <- round(mean(rawdata_results_biosses_filtered$rel_error_WBSM_AncSPLRada), 3)
mean_error_bio_embedding_intrinsic <- round(mean(rawdata_results_biosses_filtered$rel_error_bio_embedding_intrinsic), 3)
mean_error_oubiobert <- round(mean(rawdata_results_biosses_filtered$rel_error_oubiobert.base.uncased_tok.wordpiecetokenizer_lc_sw.nonestopwords_cf.default_ner.none), 3)

# Get the density estimate
density_LiBlock=density(rawdata_results_biosses_filtered$rel_error_LiBlock)
plot(density_LiBlock$x,density_LiBlock$y,type="l", col=rgb(0,0,1), xlim=c(-1,1), main="Probability Density Function (PDF) of the similarity error function",xlab="Similarity error = Estimated similarity value - Normalized human score",ylab="Frequency of error")

density_LiBlock
density_WBSM_AncSPLRada=density(rawdata_results_biosses_filtered$rel_error_WBSM_AncSPLRada)
lines(density_WBSM_AncSPLRada$x,density_WBSM_AncSPLRada$y,type="l", col=rgb(1,0,0))

density_bio_embedding_intrinsic=density(rawdata_results_biosses_filtered$rel_error_bio_embedding_intrinsic)
lines(density_bio_embedding_intrinsic$x,density_bio_embedding_intrinsic$y,type="l", col=rgb(0,1,0))

density_oubiobert=density(rawdata_results_biosses_filtered$rel_error_oubiobert.base.uncased_tok.wordpiecetokenizer_lc_sw.nonestopwords_cf.default_ner.none)
lines(density_oubiobert$x,density_oubiobert$y,type="l", col=rgb(0,1,1))

legend("topleft", c(
  paste("LiBlock (M4) (mean val. ", mean_error_liblock,")", sep=""), 
  paste("WBSM_Rada (M7) (mean val. ", mean_error_WBSM_AncSPLRada,")", sep=""), 
  paste("BioWordVec_int (26) (mean val. ", mean_error_bio_embedding_intrinsic,")", sep=""), 
  paste("ouBioBERT (M47) (mean val. ", mean_error_oubiobert,")", sep="")), 
  col=c(rgb(0,0,1), rgb(1,0,0),rgb(0,1,0),rgb(0,1,1)), lwd=10)
