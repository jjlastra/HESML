# Description:
#
# This script loads a collection of benchmarks among the
# UMLS::Similarity [1], SML [2] and HESML [3,4] semantic
# measures libraries. We compute the average speed and
# some Pearson and Spearman correlation metrics reportd in
# paper [4].
#
# References:
#
# [1] B.T. McInnes, T. Pedersen, S.V.S. Pakhomov,
# UMLS-Interface and UMLS-Similarity : open source software for
# measuring paths and semantic similarity, in: Proc. of the Annual
# Symposium of the American Medical Informatics Association,
# ncbi.nlm.nih.gov, San Francisco, CA, 2009: pp. 431–435.
# [2] S. Harispe, S. Ranwez, S. Janaqi, J. Montmain,
# The semantic measures library and toolkit: fast computation
# of semantic similarity and relatedness using biomedical ontologies,
# Bioinformatics. 30 (2014) 740–742.
# [3] J.J. Lastra-Díaz, A. García-Serrano, M. Batet, M. Fernández, F. Chirigati,
# HESML: a scalable ontology-based semantic similarity measures library with
# a set of reproducible experiments and a replication dataset,
# Information Systems. 66 (2017) 97–118.
# [4] J.J. Lastra-Díaz, A. Lara-Clares, A. García-Serrano,
# HESML: a real-time semantic measures library for the biomedical
# domain with a reproducible survey, Submitted for Publication. (2020).
# ----------

# We clear all session variables

rm(list = ls())

# IMPORTANT:configuration of the input/output directories
# We define below the input directory for the input raw results
# in CSV file format, and the output directory for the
# final assembled tables in CSV file format.
# You must change these values in order to
# point to the proper directories in your hard drive.
# We also define below the name of the input raw CSV files
# containing the experimental results.

# The input and output directories below must end with '/' in
# Unix-like format to be compatible with Windows
# or Linux-based R distributions.

# First, we get the current file script directory

current_working_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)

# and we set the working directory for the R project

setwd(current_working_dir)

# We set the input and output directories

rootDir = "../HESMLV1R5_paper/RawOutputFiles/antes/"
inputDir = rootDir
outputDir = "../HESMLV1R5_paper/ProcessedOutputFiles/"

# ------------------------------------------------------------------------
# Table 1: Average speed in concepts per second in the SNOMED-CT ontology
# ------------------------------------------------------------------------

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_Rada_SNOMEDCT_US <- read.csv(paste(inputDir, sep = "", "raw_output_Rada_SNOMEDCT_US.csv"), dec = ".", sep = ';')
rawdata_AncSPLRada_SNOMEDCT_US <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_SNOMEDCT_US.csv"), dec = ".", sep = ';')
rawdata_Lin_SNOMEDCT_US <- read.csv(paste(inputDir, sep = "", "raw_output_Lin_SNOMEDCT_US.csv"), dec = ".", sep = ';')
rawdata_WuPalmer_SNOMEDCT_US <- read.csv(paste(inputDir, sep = "", "raw_output_WuPalmerFast_SNOMEDCT_US.csv"), dec = ".", sep = ';')

# We create the table 1 as reported in the paper [4]

table1 <- matrix(nrow = 4, ncol = 5);

colnames(table1) <- c("Similarity measure", "Measure type", "UMLS::Sim", "SML", "HESML");

# We fill the row reporting the evaluation of the Rada measure

table1[1,1] = "Rada";
table1[1,2] = "edge-counting";
table1[1,3] = round(rawdata_Rada_SNOMEDCT_US[1,2] / mean(rawdata_Rada_SNOMEDCT_US[2:6,3]), digits = 3)
table1[1,4] = "xxx";
table1[1,5] = round(rawdata_Rada_SNOMEDCT_US[1,4] / mean(rawdata_Rada_SNOMEDCT_US[2:6,5]), digits = 3)

table1[2,1] = "AnsSPLRada";
table1[2,2] = "edge-counting";
table1[2,3] = "---";
table1[2,4] = "---";
table1[2,5] = round(rawdata_AncSPLRada_SNOMEDCT_US[1,4] / mean(rawdata_AncSPLRada_SNOMEDCT_US[2:6,5]), digits = 3)

table1[3,1] = "Lin";
table1[3,2] = "IC-based";
table1[3,3] = round(rawdata_Lin_SNOMEDCT_US[1,2] / mean(rawdata_Lin_SNOMEDCT_US[2:6,3]), digits = 3)
table1[3,4] = round(rawdata_Lin_SNOMEDCT_US[1,6] / mean(rawdata_Lin_SNOMEDCT_US[2:6,7]), digits = 3)
table1[3,5] = round(rawdata_Lin_SNOMEDCT_US[1,4] / mean(rawdata_Lin_SNOMEDCT_US[2:6,5]), digits = 3)

table1[4,1] = "Wu-Palmer_fast";
table1[4,2] = "depth-based";
table1[4,3] = round(rawdata_WuPalmer_SNOMEDCT_US[1,2] / mean(rawdata_WuPalmer_SNOMEDCT_US[2:6,3]), digits = 3)
table1[4,4] = "---";
table1[4,5] = round(rawdata_WuPalmer_SNOMEDCT_US[1,4] / mean(rawdata_WuPalmer_SNOMEDCT_US[2:6,5]), digits = 3)

# ------------------------------------------------------------------------
# Table 2: Average speed in concepts per second in the MeSH ontology
# ------------------------------------------------------------------------

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_Rada_MeSH <- read.csv(paste(inputDir, sep = "", "raw_output_Rada_MeSH.csv"), dec = ".", sep = ';')
rawdata_AncSPLRada_MeSH <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_MeSH.csv"), dec = ".", sep = ';')
rawdata_Lin_MeSH <- read.csv(paste(inputDir, sep = "", "raw_output_Lin_MeSH.csv"), dec = ".", sep = ';')
rawdata_WuPalmer_MeSH <- read.csv(paste(inputDir, sep = "", "raw_output_WuPalmerFast_MeSH.csv"), dec = ".", sep = ';')

# We create the table 2 as reported in the paper [4]

table2 <- matrix(nrow = 4, ncol = 5);

colnames(table2) <- c("Similarity measure", "Measure type", "UMLS::Sim", "SML", "HESML");

# We fill the row reporting the evaluation of the Rada measure

table2[1,1] = "Rada";
table2[1,2] = "edge-counting";
table2[1,3] = round(rawdata_Rada_MeSH[1,2] / mean(rawdata_Rada_MeSH[2:6,3]), digits = 3)
table2[1,4] = round(rawdata_Rada_MeSH[1,6] / mean(rawdata_Rada_MeSH[2:6,7]), digits = 3)
table2[1,5] = round(rawdata_Rada_MeSH[1,4] / mean(rawdata_Rada_MeSH[2:6,5]), digits = 3)

table2[2,1] = "AnsSPLRada";
table2[2,2] = "edge-counting";
table2[2,3] = "---";
table2[2,4] = "---";
table2[2,5] = round(rawdata_AncSPLRada_MeSH[1,4] / mean(rawdata_AncSPLRada_MeSH[2:6,5]), digits = 3)

table2[3,1] = "Lin";
table2[3,2] = "IC-based";
table2[3,3] = round(rawdata_Lin_MeSH[1,2] / mean(rawdata_Lin_MeSH[2:6,3]), digits = 3)
table2[3,4] = round(rawdata_Lin_MeSH[1,6] / mean(rawdata_Lin_MeSH[2:6,7]), digits = 3)
table2[3,5] = round(rawdata_Lin_MeSH[1,4] / mean(rawdata_Lin_MeSH[2:6,5]), digits = 3)

table2[4,1] = "Wu-Palmer_fast";
table2[4,2] = "depth-based";
table2[4,3] = round(rawdata_WuPalmer_MeSH[1,2] / mean(rawdata_WuPalmer_MeSH[2:6,3]), digits = 3)
table2[4,4] = "---";
table2[4,5] = round(rawdata_WuPalmer_MeSH[1,4] / mean(rawdata_WuPalmer_MeSH[2:6,5]), digits = 3)

# ------------------------------------------------------------------------
# Table 3: Average speed in the evaluation of the semantic simialirity
# between 30 sentence pairs of the MedSTS [1] dataset with the the MeSH
# ontology.
#
# [1] Y. Wang, N. Afzal, S. Fu, L. Wang, F. Shen, M. Rastegar-Mojarad, H. Liu,
# MedSTS: a resource for clinical semantic textual similarity,
# Language Resources and Evaluation. (2018) 1–16.
# ------------------------------------------------------------------------

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_Rada_MedSTS <- read.csv(paste(inputDir, sep = "", "raw_output_Rada_MedSTS.csv"), dec = ".", sep = ';')
rawdata_AncSPLRada_MedSTS <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_MedSTS.csv"), dec = ".", sep = ';')
rawdata_Lin_MedSTS <- read.csv(paste(inputDir, sep = "", "raw_output_Lin_MedSTS.csv"), dec = ".", sep = ';')
rawdata_WuPalmer_MedSTS <- read.csv(paste(inputDir, sep = "", "raw_output_WuPalmerFast_MedSTS.csv"), dec = ".", sep = ';')

# We create the table 4 as reported in the paper [4]

table3 <- matrix(nrow = 4, ncol = 5);

colnames(table3) <- c("Similarity measure", "Measure type", "UMLS::Sim", "SML", "HESML");

# SML library uses caching to store the similarity values. For this reason,
# we only consider the first value for a fair comparison.

# We fill the row reporting the evaluation of the Rada measure

table3[1,1] = "Rada";
table3[1,2] = "edge-counting";
table3[1,3] = round(30 / mean(rawdata_Rada_MedSTS[1:5,2]), digits = 3)
table3[1,4] = round(30 / rawdata_Rada_MedSTS[1,3], digits = 3)
table3[1,5] = round(30 / mean(rawdata_Rada_MedSTS[1:5,4]), digits = 3)

table3[2,1] = "AnsSPLRada";
table3[2,2] = "edge-counting";
table3[2,3] = "---";
table3[2,4] = "---";
table3[2,5] = round(30 / mean(rawdata_AncSPLRada_MedSTS[1:5,4]), digits = 3)

table3[3,1] = "Lin";
table3[3,2] = "IC-based";
table3[3,3] = round(30 / mean(rawdata_Lin_MedSTS[1:5,2]), digits = 3)
table3[3,4] = round(30 / mean(rawdata_Lin_MedSTS[1:5,3]), digits = 3)
table3[3,5] = round(30 / mean(rawdata_Lin_MedSTS[1:5,4]), digits = 3)

table3[4,1] = "Wu-Palmer_fast";
table3[4,2] = "depth-based";
table3[4,3] = round(30 / mean(rawdata_WuPalmer_MedSTS[1:5,2]), digits = 3)
table3[4,4] = "---";
table3[4,5] = round(30 / mean(rawdata_WuPalmer_MedSTS[1:5,4]), digits = 3)

# ------------------------------------------------------------------------
# Table 4: Pearson and Spearman correlantion between base path-based measures
# and their AncSPL variant
# ------------------------------------------------------------------------

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_AncSPLRada_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_exp4.csv"), dec = ".", sep = ';')
rawdata_AncSPLLeacock_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLLeacockChodorow_exp4.csv"), dec = ".", sep = ';')
rawdata_AncSPLCosine_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLCosineNormWeightedJiangConrath_exp4.csv"), dec = ".", sep = ';')
# rawdata_AncSPLCai_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLCaiStrategy1_exp4.csv"), dec = ".", sep = ';')

# We create the table 5 as reported in the paper [4]

table4 <- matrix(nrow = 3, ncol = 10);

colnames(table4) <- c("Base measure", "AncSPL reformulation", "Pearson", "Spearman", "Pearson", "Spearman", "Pearson", "Spearman", "Pearson", "Spearman");

# We select the number of random rows to be used for each range of results

n_samples_1 <- 50
n_samples_2 <- 100
n_samples_3 <- 200
n_samples_4 <- 1000

n_samples_1 <- 10
n_samples_2 <- 20
n_samples_3 <- 30
n_samples_4 <- 50

# We select the sample tables for each part of the experiment 4

rawdata_AncSPLRada_exp4_sample_rows_1 <- head(rawdata_AncSPLRada_exp4,n_samples_1)
rawdata_AncSPLRada_exp4_sample_rows_2 <- head(rawdata_AncSPLRada_exp4,n_samples_2)
rawdata_AncSPLRada_exp4_sample_rows_3 <- head(rawdata_AncSPLRada_exp4,n_samples_3)
rawdata_AncSPLRada_exp4_sample_rows_4 <- head(rawdata_AncSPLRada_exp4,n_samples_4)

rawdata_AncSPLLeacock_exp4_sample_rows_1 <- head(rawdata_AncSPLLeacock_exp4,n_samples_1)
rawdata_AncSPLLeacock_exp4_sample_rows_2 <- head(rawdata_AncSPLLeacock_exp4,n_samples_2)
rawdata_AncSPLLeacock_exp4_sample_rows_3 <- head(rawdata_AncSPLLeacock_exp4,n_samples_3)
rawdata_AncSPLLeacock_exp4_sample_rows_4 <- head(rawdata_AncSPLLeacock_exp4,n_samples_4)

rawdata_AncSPLCosine_exp4_sample_rows_1 <- head(rawdata_AncSPLCosine_exp4,n_samples_1)
rawdata_AncSPLCosine_exp4_sample_rows_2 <- head(rawdata_AncSPLCosine_exp4,n_samples_2)
rawdata_AncSPLCosine_exp4_sample_rows_3 <- head(rawdata_AncSPLCosine_exp4,n_samples_3)
rawdata_AncSPLCosine_exp4_sample_rows_4 <- head(rawdata_AncSPLCosine_exp4,n_samples_4)

# We fill the row reporting the evaluation of the Rada measure

table4[1,1] = "Rada";
table4[1,2] = "AnsSPL-Rada";
table4[1,3] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_1[,3], rawdata_AncSPLRada_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table4[1,4] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_1[,3], rawdata_AncSPLRada_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table4[1,5] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_2[,3], rawdata_AncSPLRada_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table4[1,6] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_2[,3], rawdata_AncSPLRada_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table4[1,7] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_3[,3], rawdata_AncSPLRada_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table4[1,8] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_3[,3], rawdata_AncSPLRada_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table4[1,9] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_4[,3], rawdata_AncSPLRada_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table4[1,10] = round(cor(rawdata_AncSPLRada_exp4_sample_rows_4[,3], rawdata_AncSPLRada_exp4_sample_rows_4[, 4], method = "spearman"), 4)

table4[2,1] = "Leacock-Chodorow";
table4[2,2] = "AnsSPL-Leacock";
table4[2,3] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_1[,3], rawdata_AncSPLLeacock_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table4[2,4] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_1[,3], rawdata_AncSPLLeacock_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table4[2,5] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_2[,3], rawdata_AncSPLLeacock_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table4[2,6] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_2[,3], rawdata_AncSPLLeacock_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table4[2,7] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_3[,3], rawdata_AncSPLLeacock_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table4[2,8] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_3[,3], rawdata_AncSPLLeacock_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table4[2,9] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_4[,3], rawdata_AncSPLLeacock_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table4[2,10] = round(cor(rawdata_AncSPLLeacock_exp4_sample_rows_4[,3], rawdata_AncSPLLeacock_exp4_sample_rows_4[, 4], method = "spearman"), 4)

table4[3,1] = "coswJ&C";
table4[3,2] = "AnsSPL-coswJ&C";
table4[3,3] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_1[,3], rawdata_AncSPLCosine_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table4[3,4] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_1[,3], rawdata_AncSPLCosine_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table4[3,5] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_2[,3], rawdata_AncSPLCosine_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table4[3,6] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_2[,3], rawdata_AncSPLCosine_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table4[3,7] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_3[,3], rawdata_AncSPLCosine_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table4[3,8] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_3[,3], rawdata_AncSPLCosine_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table4[3,9] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_4[,3], rawdata_AncSPLCosine_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table4[3,10] = round(cor(rawdata_AncSPLCosine_exp4_sample_rows_4[,3], rawdata_AncSPLCosine_exp4_sample_rows_4[, 4], method = "spearman"), 4)

table4[4,1] = "Cai";
table4[4,2] = "AnsSPL-Cai";
table4[4,3] = round(cor(rawdata_AncSPLCai_exp4_sample_rows_1[,3], rawdata_AncSPLCai_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table4[4,4] = round(cor(rawdata_AncSPLCai_exp4_sample_rows_1[,3], rawdata_AncSPLCai_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table4[4,5] = round(cor(rawdata_AncSPLCai_exp4_sample_rows_2[,3], rawdata_AncSPLCai_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table4[4,6] = round(cor(rawdata_AncSPLCai_exp4_sample_rows_2[,3], rawdata_AncSPLCai_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table4[4,7] = round(cor(rawdata_AncSPLCai_exp4_sample_rows_3[,3], rawdata_AncSPLCai_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table4[4,8] = round(cor(rawdata_AncSPLCai_exp4_sample_rows_3[,3], rawdata_AncSPLCai_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table4[4,9] = round(cor(rawdata_AncSPLCai_exp4_sample_rows_4[,3], rawdata_AncSPLCai_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table4[4,10] = round(cor(rawdata_AncSPLCai_exp4_sample_rows_4[,3], rawdata_AncSPLCai_exp4_sample_rows_4[, 4], method = "spearman"), 4)

# ------------------------------------------------------------------------
# Table 5: Average speed in concepts per second in the GO ontology
# ------------------------------------------------------------------------

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_Rada_GO <- read.csv(paste(inputDir, sep = "", "raw_output_Rada_GO.csv"), dec = ".", sep = ';')
rawdata_AncSPLRada_GO <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_GO.csv"), dec = ".", sep = ';')
rawdata_Lin_GO <- read.csv(paste(inputDir, sep = "", "raw_output_Lin_GO.csv"), dec = ".", sep = ';')

# We create the table 1 as reported in the paper [4]

table5 <- matrix(nrow = 3, ncol = 4);

colnames(table5) <- c("Similarity measure", "Measure type", "SML", "HESML");

# We fill the row reporting the evaluation of the Rada measure

table5[1,1] = "Rada";
table5[1,2] = "edge-counting";
table5[1,3] = round(rawdata_Rada_GO[1,2] / mean(rawdata_Rada_GO[2:6,3]), digits = 3)
table5[1,4] = round(rawdata_Rada_GO[1,4] / mean(rawdata_Rada_GO[2:6,5]), digits = 3)

table5[2,1] = "AnsSPLRada";
table5[2,2] = "edge-counting";
table5[2,3] = "---";
table5[2,4] = round(rawdata_AncSPLRada_GO[1,4] / mean(rawdata_AncSPLRada_GO[2:6,5]), digits = 3)

table5[3,1] = "Lin";
table5[3,2] = "IC-based";
table5[3,3] = round(rawdata_Lin_GO[1,2] / mean(rawdata_Lin_GO[2:6,3]), digits = 3)
table5[3,4] = round(rawdata_Lin_GO[1,4] / mean(rawdata_Lin_GO[2:6,5]), digits = 3)

# ------------------------------------------------------------
# We save all final data tables 
# ------------------------------------------------------------

write.csv(table1, file = paste(outputDir, sep="","table1.csv"))
write.csv(table2, file = paste(outputDir, sep="","table2.csv"))
write.csv(table3, file = paste(outputDir, sep="","table3.csv"))
write.csv(table4, file = paste(outputDir, sep="","table4.csv"))
write.csv(table5, file = paste(outputDir, sep="","table5.csv"))

#-------------------------------
# HTML report generation
#-------------------------------

library(knitr)
library(readr)

# We load and browse Table 1 in the paper

kable_out <- kable(table1,
                   caption = "Table 1. Average speed in CUI concept pairs per second obtained for the evaluation of three representative ontology-based semantic similarity measures based on the SNOMED-CT US 2019AB ontology (Nov, 2019) implemented by the three UMLS-based semantic measures libraries reported in the literature. Best performing values are shown in bold. Non-implemented methods (---) or more than 1 hour/pair (xxx). UMLS::Similarity uses caching for the shortest path computations in edge-counting measures.",
                   format = "html",
                   align = c('l','l','c','c','c'))

readr::write_file(kable_out, "Table1.html")
browseURL("Table1.html")

# We load and browse Table 2 in the paper

kable_out <- kable(table2,
                   caption = "Table 2. Average speed in CUI concept pairs per second obtained for the evaluation of three representative ontology-based semantic similarity measures based on the MeSH 2019 ontology (Nov, 2019) implemented by the three UMLS-based semantic measures libraries reported in the literature. Best performing values are shown in bold. Non-implemented methods (---).",
                   format = "html",
                   align = c('l','l','c','c','c'))

readr::write_file(kable_out, "Table2.html")
browseURL("Table2.html")

# We load and browse Table 3 in the paper

kable_out <- kable(table3,
                   caption = "Table 3. Average speed in GO concept pairs per second obtained for the evaluation of two representative ontology-based semantic similarity measures based on the Gene Ontology (2020-05-02 version) implemented by state-of-the-art SML library and HESML. Best performing values are shown in bold.",
                   format = "html",
                   align = c('l','l','c','c'))

readr::write_file(kable_out, "Table3.html")
browseURL("Table3.html")

# We load and browse Table 4 in the paper

kable_out <- kable(table4,
                   caption = "Table 4. Average speed in sentence pairs per second obtained for the evaluation of the UBSM sentence similarity measure combined with three representative ontology-based similarity measures based on the MeSH ontology (Nov, 2019) in 30 sentence pairs from the MedSTS sentence similarity dataset (1068 sentence pairs). Best performing values are shown in bold. Non-implemented methods (---).",
                   format = "html",
                   align = c('l','l','c','c','c'))

readr::write_file(kable_out, "Table4.html")
browseURL("Table4.html")

# We load and browse Table 5 in the paper

kable_out <- kable(table5,
                   caption = "Table 5. This table shows the Pearson and Spearman correlation values between the similarity values returned by a set of path-based similarity measures and those values returned by their reformulation based on the new AncSPL algorithm introduced herein for 50 random CUI pairs. All similarity measures are implemented in HESML V1R5. CoswJ&C sets the current state-of-the-art in the family of ontology-based semantic similarity measures based on WordNet.",
                   format = "html",
                   align = c('l','l','c','c'))

readr::write_file(kable_out, "Table5.html")
browseURL("Table5.html")


#############################
# we export the latex Table 5
#############################

library(knitr)
library(readr)
library(kableExtra)
library(stringr)
library(xtable)

# We define the latex table with the data

colnames(table4) <- c("Base measure", "\\makecell[c]{AncSPL \\\\ reformulation}", "r", '$\\rho$', "r", '$\\rho$', "r", '$\\rho$', "r", '$\\rho$');

table4[1,1] = "Rada \\cite{Rada1989-cv}";
table4[2,1] = "\\makecell[l]{Leacock and \\\\ Chodorow \\cite{Leacock1998-hr}}";
table4[3,1] = "coswJ\\&C \\cite{Lastra-Diaz2015-ct}";
table4[3,2] = "AnsSPL-coswJ\\&C";


table_latex <- xtable(table4, type = "latex", digits=4, method = "compact")

# We add extra rows to the table before printing it

addtorow      <- list()
addtorow$pos  <- list()

# We add an extra header with the dataset groups

addtorow$pos[[1]] <- -1
addtorow$command  <- c('\\hline \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} & \\multicolumn{2}{c}{\\underline{50 samples} & \\multicolumn{2}{c}{\\underline{100 samples} & \\multicolumn{2}{c}{\\underline{200 samples} & \\multicolumn{2}{c}{\\underline{1000 samples} \\\\ ')

# we define a function for adding \small to all rows. 

add_small_to_all_rows.allrows <- function(x) {
  x # this function returns the same input value, only for tests
}

#add_small_to_all_rows.allrows <- function(x) {
#  h <- paste('\\small{',x,'}', sep ='')
#  h
#}

# We align the table 

align(table_latex) <- "llcccccccc"

# We save the tables in latex and HTML format files. The HTML format is for 

strLatexTables <- print(xtable(table_latex, caption = "WRITE_CAPTION", label = "tab:ancspl_results", digits=3), caption.placement = 'top',floating.environment = "table*",
                                                          add.to.row = addtorow, comment=FALSE, table.placement="h!", include.rownames=FALSE, 
                                                          sanitize.colnames.function = identity, sanitize.text.function =  add_small_to_all_rows.allrows)


