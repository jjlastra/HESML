# Description:
#
# This script loads a collection of sentence similarity benchmarks generated
# by HESMLSTSclient program, which contain the raw similarity values for
# sentence pair. Then, the script computes a collection of consolidated tables
# including the Pearson, Spearman and harmonic score metrics.
#
# References:
# ----------

# We clear all session variables

rm(list = ls())

# IMPORTANT:configuration of the input/output directories
# We define below the input directory for the input raw results
# in CSV file format, and the output directory for the
# final assembled tables in CSV file format.
# You must change these values in order to
# point to the proper directories in your hard drive.
# We also define below the name of the input raw CSV files
# containing the experimental results.

# The input and output directories below must end with '/' in
# Unix-like format to be compatible with Windows
# or Linux-based R distributions.

# First, we get the current file script directory

current_working_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)

# and we set the working directory for the R project

setwd(current_working_dir)

# Define the root path 

rootDir = "../BioSentenceSimilarity_paper"


# We import the library that implements the data structures.

library(collections)

# We create an OrderedDict object with all the experiments that will be evaluated.

experiments <- ordered_dict()

# We define the subdirectory experiment and the caption for showing the results in Latex and HTML format
# and we add to the dictionary all the String-based measures experiments

experimentSubdirectory = "BioSentenceSimFinalRawOutputFiles"
preprocessedExperimentsSubdirectory = "BioSentenceSimFinalProcessedOutputFiles"


# We create a Dictionary object for printing the Latex tables with the captions

latexTables <- ordered_dict()

# We define the output directory 

dir.create(paste(rootDir, "/", preprocessedExperimentsSubdirectory, "/", sep = ""))
outputDir =  paste(rootDir, "/", preprocessedExperimentsSubdirectory, "/", sep = "")

# We create a list for each output table

rawdata_experiments <- list()

# Input raw CSV files generated by the reproducible experiments detailed
# in the companion paper for each sentence similarity dataset

# We define the input datasets directories

inputDir = paste(rootDir, "/", experimentSubdirectory, "/", sep = "")

# We initialize the counter of executions

counter_executions <- 0

# We initialize the string with the latex tables output. We will print all at the end of the script

strLatexTables <- ""

# We load the input raw results file for best combinations (FINAL RESULTS)

source(paste("bio_sentence_sim_scripts", "readBESTCOMBS.R", sep = "/"), local = knitr::knit_global())

# We get the label

experimentLabel = rawdata_BESTCOMBS$label

# We update the counter with the number of columns (the number the experiments that are in the table)

counter_executions <- counter_executions + ncol(rawdata_BESTCOMBS$biosses) - 1

# We get the experiment subdirectory and the caption for the Latex File

strCaption = paste("Pearson (r), Spearman ($\\rho$), Harmonic ($h$) and harmonic average (AVG) scores obtained by each sentence similarity method evaluated herein in the three biomedical sentence similarity benchmarks arranged by families. The resulting values have been computed using the best pre-processing configuration obtained from table \\ref{tab:table_pre-processing_methods_selected}.", sep="")

rawdata_BIOSSES <- rawdata_BESTCOMBS$biosses
rawdata_MedSTS  <- rawdata_BESTCOMBS$medsts
rawdata_CTR     <- rawdata_BESTCOMBS$ctr

# mat.sort function is copied from source files of
# BioPhysConnectoR package which is now unavailable.
# Source code was retrieved from https://rdrr.io/cran/BioPhysConnectoR/src/R/mat.sort.r

# mat.sort<-function(mat,sort,decreasing=FALSE)
# {
#   m<-do.call("order",c(as.data.frame(mat[,sort]),decreasing=decreasing))
#   mat[m,]
# }

# ---------------------------------------------------------------------
# Raw output file format:
# Raw similarity files contain the similarity values returned by each
# semantic measure for each sentence pair. 
# First column contains the uman judgements for each sentence pair
# whilst subsequent columns contain the values returned by the
# sentence similaritu measures.
# ---------------------------------------------------------------------

# ---------------------------------------------------------------------
# Table 1: Pearson and Spearman metrics of all sentence similarity
# measures.
# ---------------------------------------------------------------------

# We define all datasets represented in table 1

rawdata_allDatasets <- list(rawdata_BIOSSES, rawdata_MedSTS, rawdata_CTR)

# We create a separated table for each metric by removing the first column
# which contains the human judgements. Measures are arranged in rows
# whilst datasets are arranged in columns.

table_Pearson <- matrix(nrow = ncol(rawdata_BIOSSES) - 1,
                        ncol = length(rawdata_allDatasets),
                        dimnames = list(colnames(rawdata_BIOSSES)[2:ncol(rawdata_BIOSSES)],
                                        c("BIOSSES", "MedSTS", "CTR")))

table_Spearman <- table_Pearson
table_Harmonic <- table_Pearson

# Loop for the computation of the metrics

nMeasures <- nrow(table_Pearson)
nDatasets <- length(rawdata_allDatasets)

for (iDataset in 1:nDatasets)
{
  # We get the raw data of the next dataset
  
  rawdata <- rawdata_allDatasets[[iDataset]]
  
  # We evaluate the Pearson and Spearman metrics for each measure in the current dataset
  
  for (iMeasure in 1:nMeasures)
  {
    rawdata[,1]
    rawdata[, iMeasure + 1]
    
    table_Pearson[iMeasure, iDataset] <- cor(rawdata[,1], rawdata[, iMeasure + 1], use="complete.obs", method = "pearson")
    table_Spearman[iMeasure, iDataset] <- cor(rawdata[,1], rawdata[, iMeasure + 1], use="complete.obs", method = "spearman")
    table_Harmonic[iMeasure, iDataset] <- 2 * table_Pearson[iMeasure, iDataset] * table_Spearman[iMeasure, iDataset] / (table_Pearson[iMeasure, iDataset] + table_Spearman[iMeasure, iDataset])
  }
}

# ------------------------------------------------------------
# We merge all metrics (Pearson, Spearman and Harmonic score)
# into a same data table by concatening previouos data tables.
# ------------------------------------------------------------

table_allMetrics <- cbind(table_Pearson, table_Spearman, table_Harmonic, Avg = rowMeans(table_Harmonic[1:nrow(table_Harmonic),]))

# table_allMetrics <- cbind(table_Pearson, table_Spearman, Avg = rowMeans(table_Harmonic[1:nrow(table_Harmonic),]))

# table_allMetrics <- mat.sort(table_allMetrics, ncol(table_allMetrics), decreasing = TRUE)
# table_allMetrics <- mat.sort(table_allMetrics, 1, decreasing = TRUE)

table_allMetrics <- table_allMetrics[order(rownames(table_allMetrics)),] # where y is a 2D array of your data

# We set the column names to the final matrix

colnames(table_allMetrics) <- c("r", "r", "r",
                                '$\\rho$', '$\\rho$', '$\\rho$',
                                "h", "h", "h",
                                "Avg")
# colnames(table_allMetrics) <- c("r", "r", "r",
#                                 '$\\rho$', '$\\rho$', '$\\rho$',
#                                 "Avg")

# We reorder the matrix columns grouping by dataset names.

table_allMetrics <- table_allMetrics[ , c(1,4,7,2,5,8,3,6,9,10) ]
# table_allMetrics <- table_allMetrics[ , c(1,4,2,5,3,6,7) ]

# We make a copy of the tables in order to round their values to 3 decimal digits

table_allMetrics_rounded <- round(table_allMetrics, 3);

table_allMetrics_rounded <- as.data.frame(table_allMetrics_rounded)
table_allMetrics_rounded

# Remove extra rows

table_allMetrics_rounded[!grepl("Human", table_allMetrics_rounded[0]),]

# We save all final assembled data tables 

write.csv(table_allMetrics, file = paste(outputDir,"table_allMetrics_", experimentLabel, ".csv", sep=""))
write.csv(table_allMetrics_rounded, file = paste(outputDir, "table_allMetrics_rounded_", experimentLabel, ".csv", sep=""))

# We add the output table to the Latex dictionary

latexTables$set(strCaption, table_allMetrics_rounded)

#-------------------------------
# LATEX report generation
# 
# IMPORTANT NOTE: To avoid the problem of oversizing the box, add manually the next command BEFORE tabular:
#
# \resizebox{\columnwidth}{!}{%
#
# TABLE DATA
#
# }
# \end{table}
#-------------------------------

library(knitr)
library(readr)
library(kableExtra)
library(stringr)
library(xtable)

# We define the latex table with the data

table_latex <- xtable(table_allMetrics_rounded, type = "latex", digits=4, method = "compact")

# We add extra rows to the table before printing it

addtorow      <- list()
addtorow$pos  <- list()

# We add an extra header with the dataset groups

addtorow$pos[[1]] <- -1
addtorow$command  <- c('\\hline & \\multicolumn{1}{c}{ } & \\multicolumn{3}{c}{BIOSSES} & \\multicolumn{3}{c}{MedSTS} & \\multicolumn{3}{c}{CTR} & \\multicolumn{1}{c}{Avg} \\\\ ')

tableLatex <- print(xtable(table_latex, caption = strCaption, digits=3), caption.placement = 'top',
                    add.to.row = addtorow, comment=FALSE, size="\\tiny", table.placement="!h", sanitize.colnames.function = identity)

# Replace all the method names with the cites

tableLatex <- gsub("Qgram", 'M1 & Qgram \\cite{Ukkonen1992-uf}', tableLatex, fixed=TRUE)
tableLatex <- gsub("Jaccard", 'M2 & Jaccard \\cite{Jaccard1908-hk, Manning1999-ja}', tableLatex, fixed=TRUE)
tableLatex <- gsub("BlockDistance", 'M3 & Block distance \\cite{Krause1986-wb}', tableLatex, fixed=TRUE)
tableLatex <- gsub("LiMixed", 'M4 & LiMixed (this work)', tableLatex, fixed=TRUE)
tableLatex <- gsub("Levenshtein", 'M5 & Levenshtein distance \\cite{Levenshtein1966-by}', tableLatex, fixed=TRUE)
tableLatex <- gsub("OverlapCoefficient", 'M6 & Overlap coefficient \\cite{Lawlor1980-pm}', tableLatex, fixed=TRUE)
tableLatex <- gsub("COM\\_WBSM\\_AncSPLRada\\_UBSM\\_AncSPLWeightedJiangConrath", 'M17 & \\makecell[l]{COM-Rada-cosJ\\&C (this work)', tableLatex, fixed=TRUE)
tableLatex <- gsub("WBSM\\_AncSPLRada", 'M7 & WBSM-Rada \\cite{Sogancioglu2017-rc,Rada1989-cv,lastra-diaz2022}', tableLatex, fixed=TRUE)
tableLatex <- gsub("WBSM\\_JiangConrath", 'M8 & WBSM-J\\&C \\cite{Sogancioglu2017-rc,Jiang1997-zz}', tableLatex, fixed=TRUE)
tableLatex <- gsub("WBSM\\_AncSPLWeightedJiangConrath", 'M9 & WBSM-cosJ\\&C (this work) \\cite{Sogancioglu2017-rc,Lastra-Diaz2015-ct,Sanchez2011-cf,lastra-diaz2022}', tableLatex, fixed=TRUE)
tableLatex <- gsub("WBSM\\_AncSPLCosineNormWeightedJiangConrath", 'M10 & WBSM-coswJ\\&C (this work) \\cite{Sogancioglu2017-rc,Lastra-Diaz2015-ct,Sanchez2011-cf,lastra-diaz2022}', tableLatex, fixed=TRUE)
tableLatex <- gsub("WBSM\\_AncSPLCaiStrategy1", 'M11 & WBSM-Cai \\cite{Sogancioglu2017-rc,Cai2017-di,lastra-diaz2022}', tableLatex, fixed=TRUE)
tableLatex <- gsub("UBSM\\_AncSPLRada", 'M12 & UBSM-Rada \\cite{Sogancioglu2017-rc,Rada1989-cv,lastra-diaz2022}', tableLatex, fixed=TRUE)
tableLatex <- gsub("UBSM\\_JiangConrath", 'M13 & UBSM-J\\&C \\cite{Sogancioglu2017-rc,Jiang1997-zz}', tableLatex, fixed=TRUE)
tableLatex <- gsub("UBSM\\_AncSPLWeightedJiangConrath", 'M14 & UBSM-cosJ\\&C (this work) \\cite{Sogancioglu2017-rc,Lastra-Diaz2015-ct,Sanchez2011-cf,lastra-diaz2022}', tableLatex, fixed=TRUE)
tableLatex <- gsub("UBSM\\_AncSPLCosineNormWeightedJiangConrath", 'M15 & UBSM-coswJ\\&C (this work) \\cite{Sogancioglu2017-rc,Lastra-Diaz2015-ct,Sanchez2011-cf,lastra-diaz2022}', tableLatex, fixed=TRUE)
tableLatex <- gsub("UBSM\\_AncSPLCaiStrategy1", 'M16 & UBSM-Cai \\cite{Sogancioglu2017-rc,Cai2017-di,lastra-diaz2022}', tableLatex, fixed=TRUE)
tableLatex <- gsub("Flair", 'M18 & Flair \\cite{Tawfik2020-uo,Akbik2018-fh}', tableLatex, fixed=TRUE)
tableLatex <- gsub("PubMed.and.PMC.w2v", 'M19 & Pyysalo et al. \\cite{Pyysalo2013-jy}', tableLatex, fixed=TRUE)
tableLatex <- gsub("bioconceptvec\\_word2vec\\_skipgram", 'M20 & BioConceptVec$_{word2vec\\_sg}$', tableLatex, fixed=TRUE)
tableLatex <- gsub("bioconceptvec\\_word2vec\\_cbow", 'M21 & BioConceptVec$_{word2vec\\_cbow}$', tableLatex, fixed=TRUE)
tableLatex <- gsub("PubMed\\_SkipGramNegSampling", 'M22 & Newman-Griffis$_{word2vec\\_sgns}$ \\cite{Newman-Griffis2017-mz}', tableLatex, fixed=TRUE)
tableLatex <- gsub("PubMed\\_CBOW", 'M23 & Newman-Griffis$_{word2vec\\_cbow}$ \\cite{Newman-Griffis2017-mz}', tableLatex, fixed=TRUE)
tableLatex <- gsub("PubMed\\_Glove", 'M24 & Newman-Griffis$_{glove}$', tableLatex, fixed=TRUE)
tableLatex <- gsub("bioconceptvec\\_glove", 'M25 & BioConceptVec$_{glove}$ \\cite{Chen2019-jo}', tableLatex, fixed=TRUE)
tableLatex <- gsub("bio\\_embedding\\_intrinsic", 'M26 & BioWordVec$_{int}$ \\cite{Zhang2019-qq}', tableLatex, fixed=TRUE)
tableLatex <- gsub("bio\\_embedding\\_extrinsic", 'M27 & BioWordVec$_{ext}$ \\cite{Zhang2019-qq}', tableLatex, fixed=TRUE)
tableLatex <- gsub("BioNLP2016\\_PubMed.shuffle.win.2", 'M28 & BioNLP2016$_{win2}$ \\cite{Chiu2016-bs}', tableLatex, fixed=TRUE)
tableLatex <- gsub("BioNLP2016\\_PubMed.shuffle.win.30", 'M29 & BioNLP2016$_{win30}$ \\cite{Chiu2016-bs}', tableLatex, fixed=TRUE)
tableLatex <- gsub("bioconceptvec\\_fasttext", 'M30 & BioConceptVec$_{fastText}$', tableLatex, fixed=TRUE)
tableLatex <- gsub("USE", 'M31 & USE \\cite{Cer2018-cr}', tableLatex, fixed=TRUE)
tableLatex <- gsub("Sent2vec\\_BioSentVec\\_PubMed\\_MIMICIII.bigram\\_d700", 'M32 & BioSentVec (PubMed+MIMIC-III) \\cite{Chen2018-uh}', tableLatex, fixed=TRUE)
tableLatex <- gsub("bioc\\_skipgram\\_defaultchar\\_Min", 'M33 & FastText-SkGr-BioC (this work)', tableLatex, fixed=TRUE)
tableLatex <- gsub("biobert\\_v1.0\\_pubmed\\_tok.wordpiecetokenizer\\_lc\\_sw.nonestopwords\\_cf.biosses\\_ner.none", 'M34 & BioBERT Base 1.0 (+ PubMed)', tableLatex, fixed=TRUE)
tableLatex <- gsub("biobert\\_v1.0\\_pmc\\_tok.wordpiecetokenizer\\_lc\\_sw.nonestopwords\\_cf.biosses\\_ner.none", 'M35 & BioBERT Base 1.0 (+ PMC)', tableLatex, fixed=TRUE)
tableLatex <- gsub("biobert\\_v1.0\\_pubmed\\_pmc\\_tok.wordpiecetokenizer\\_lc\\_sw.nonestopwords\\_cf.biosses\\_ner.none", 'M36 & \\makecell[l]{BioBERT Base 1.0 (PubMed+PMC)}', tableLatex, fixed=TRUE)
tableLatex <- gsub("biobert\\_v1.1\\_pubmed\\_tok.wordpiecetokenizer\\_notlc\\_sw.nltk2018stopwords\\_cf.blagec2019\\_ner.none", 'M37 & BioBERT Base 1.1 (+ PubMed)', tableLatex, fixed=TRUE)
tableLatex <- gsub("biobert\\_large\\_v1.1\\_pubmed\\_tok.wordpiecetokenizer\\_notlc\\_sw.nltk2018stopwords\\_cf.blagec2019\\_ner.none", 'M38 & BioBERT Large 1.1 (+ PubMed)', tableLatex, fixed=TRUE)
tableLatex <- gsub("ncbi\\_bert\\_pubmed\\_uncased\\_l.12\\_h.768\\_a.12\\_tok.wordpiecetokenizer\\_lc\\_sw.nonestopwords\\_cf.blagec2019\\_ner.none", 'M39 & NCBI-BlueBERT Base PubMed', tableLatex, fixed=TRUE)
tableLatex <- gsub("ncbi\\_bert\\_pubmed\\_uncased\\_l.24\\_h.1024\\_a.16\\_tok.wordpiecetokenizer\\_lc\\_sw.nonestopwords\\_cf.biosses\\_ner.none", 'M40 & NCBI-BlueBERT Large PubMed', tableLatex, fixed=TRUE)
tableLatex <- gsub("ncbi\\_bert\\_pubmed\\_mimic\\_uncased\\_l.12\\_h.768\\_a.12\\_tok.wordpiecetokenizer\\_lc\\_sw.biosses2017stopwords\\_cf.biosses\\_ner.none", 'M41 & \\makecell[l]{NCBI-BlueBERT Base \\ PubMed + MIMIC-III} ', tableLatex, fixed=TRUE)
tableLatex <- gsub("ncbi\\_bert\\_pubmed\\_mimic\\_uncased\\_l.24\\_h.1024\\_a.16\\_tok.wordpiecetokenizer\\_lc\\_sw.nonestopwords\\_cf.biosses\\_ner.none", 'M42 & \\makecell[l]{NCBI-BlueBERT Large \\ PubMed + MIMIC-III}', tableLatex, fixed=TRUE)
tableLatex <- gsub("scibert\\_scivocab\\_uncased\\_tok.wordpiecetokenizer\\_lc\\_sw.nltk2018stopwords\\_cf.biosses\\_ner.none", 'M43 & SciBERT', tableLatex, fixed=TRUE)
tableLatex <- gsub("clinicalbert\\_tok.wordpiecetokenizer\\_notlc\\_sw.biosses2017stopwords\\_cf.blagec2019\\_ner.none", 'M44 & ClinicalBERT', tableLatex, fixed=TRUE)
tableLatex <- gsub("pubmedbert.base.uncased.abstract\\_tok.wordpiecetokenizer\\_lc\\_sw.nltk2018stopwords\\_cf.default\\_ner.none", 'M45 & PubMedBERT (abstracts)', tableLatex, fixed=TRUE)
tableLatex <- gsub("pubmedbert.base.uncased.abstract.fulltext\\_tok.wordpiecetokenizer\\_lc\\_sw.nonestopwords\\_cf.default\\_ner.none", 'M46 & \\makecell[l]{PubMedBERT (abstracts+full text)}', tableLatex, fixed=TRUE)
tableLatex <- gsub("oubiobert.base.uncased\\_tok.wordpiecetokenizer\\_lc\\_sw.nonestopwords\\_cf.default\\_ner.none", 'M47 & ouBioBERT-Base, Uncased \\cite{Wada2020-nw}', tableLatex, fixed=TRUE)
tableLatex <- gsub("bio.clinicalbert\\_tok.wordpiecetokenizer\\_lc\\_sw.biosses2017stopwords\\_cf.blagec2019\\_ner.none", 'M48 & BioClinicalBERT \\cite{Alsentzer2019-hj}', tableLatex, fixed=TRUE)
tableLatex <- gsub("bio.dischargesummarybert\\_tok.wordpiecetokenizer\\_lc\\_sw.nltk2018stopwords\\_cf.blagec2019\\_ner.none", 'M49 & BioDischargesummaryBERT \\cite{Alsentzer2019-hj}', tableLatex, fixed=TRUE)
tableLatex <- gsub("dischargesummarybert\\_tok.wordpiecetokenizer\\_notlc\\_sw.nltk2018stopwords\\_cf.blagec2019\\_ner.none", 'M50 & DischargesummaryBERT \\cite{Alsentzer2019-hj}', tableLatex, fixed=TRUE)

# Write the Latex table in a file

file_name <- paste(outputDir,"table_", experimentLabel, ".txt", sep="")

write_file(tableLatex, file_name)

# And open the table in the default file browser.

browseURL(file_name)
