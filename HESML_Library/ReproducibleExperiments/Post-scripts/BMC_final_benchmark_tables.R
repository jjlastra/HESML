# Description:
#
# This script loads a collection of benchmarks among the
# UMLS::Similarity [1], SML [2] and HESML [3,4] semantic
# measures libraries. We compute the average speed and
# some Pearson and Spearman correlation metrics reportd in
# paper [4].
#
# References:
#
# [1] B.T. McInnes, T. Pedersen, S.V.S. Pakhomov,
# UMLS-Interface and UMLS-Similarity : open source software for
# measuring paths and semantic similarity, in: Proc. of the Annual
# Symposium of the American Medical Informatics Association,
# ncbi.nlm.nih.gov, San Francisco, CA, 2009: pp. 431–435.
# [2] S. Harispe, S. Ranwez, S. Janaqi, J. Montmain,
# The semantic measures library and toolkit: fast computation
# of semantic similarity and relatedness using biomedical ontologies,
# Bioinformatics. 30 (2014) 740–742.
# [3] J.J. Lastra-Díaz, A. García-Serrano, M. Batet, M. Fernández, F. Chirigati,
# HESML: a scalable ontology-based semantic similarity measures library with
# a set of reproducible experiments and a replication dataset,
# Information Systems. 66 (2017) 97–118.
# [4] J.J. Lastra-Díaz, A. Lara-Clares, A. García-Serrano,
# HESML: a real-time semantic measures library for the biomedical
# domain with a reproducible survey, Submitted for Publication. (2020).
# ----------

# We clear all session variables

rm(list = ls())

# IMPORTANT:configuration of the input/output directories
# We define below the input directory for the input raw results
# in CSV file format, and the output directory for the
# final assembled tables in CSV file format.
# You must change these values in order to
# point to the proper directories in your hard drive.
# We also define below the name of the input raw CSV files
# containing the experimental results.

# The input and output directories below must end with '/' in
# Unix-like format to be compatible with Windows
# or Linux-based R distributions.

# First, we get the current file script directory

current_working_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)

# and we set the working directory for the R project

setwd(current_working_dir)

# We set the input and output directories

rootDir = "../HESMLV1R5_paper/RawOutputFiles/"
inputDir = rootDir
outputDir = "../HESMLV1R5_paper/ProcessedOutputFiles/"

# ------------------------------------------------------------------------
# Table 6 (in the paper), Experiment 1 in HESML_UMLS_benchmark.java: Average speed in concepts per second in the SNOMED-CT ontology
# ------------------------------------------------------------------------

caption_table6 = "Average speed in CUI concept pairs per second for the evaluation of random CUI pairs with three representative ontology-based similarity measures based on the SNOMED-CT US 2019AB ontology (357406 nodes) implemented by the three UMLS-based semantic measures libraries reported in the literature. Best performing values are shown in bold. Non-implemented methods (---) or more than 1 hour/pair (xxx). UMLS::Similarity uses caching for the shortest path computations. \\hl{The number of random CUI pairs evaluated to measure each value is shown between parentheses.}"

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_Rada_SNOMEDCT_US <- read.csv(paste(inputDir, sep = "", "raw_output_Rada_SNOMEDCT_US.csv"), dec = ".", sep = ';')
rawdata_AncSPLRada_SNOMEDCT_US <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_SNOMEDCT_US.csv"), dec = ".", sep = ';')
rawdata_Lin_SNOMEDCT_US <- read.csv(paste(inputDir, sep = "", "raw_output_Lin_SNOMEDCT_US.csv"), dec = ".", sep = ';')
rawdata_WuPalmer_SNOMEDCT_US <- read.csv(paste(inputDir, sep = "", "raw_output_WuPalmerFast_SNOMEDCT_US.csv"), dec = ".", sep = ';')

# We create the table 1 as reported in the paper [4]

table6 <- matrix(nrow = 4, ncol = 4);

colnames(table6) <- c("Similarity measure", "UMLS::Sim", "SML", "HESML");

# We fill the row reporting the evaluation of the Rada measure

table6[1,1] = "Rada";
# table6[1,2] = "edge-counting";
table6[1,2] = round(rawdata_Rada_SNOMEDCT_US[1,2] / mean(rawdata_Rada_SNOMEDCT_US[2:6,3]), digits = 3)
table6[1,3] = "xxx";
table6[1,4] = round(rawdata_Rada_SNOMEDCT_US[1,4] / mean(rawdata_Rada_SNOMEDCT_US[2:6,5]), digits = 3)

table6[2,1] = "AnsSPLRada";
# table6[2,2] = "edge-counting";
table6[2,2] = "---";
table6[2,3] = "---";
table6[2,4] = round(rawdata_AncSPLRada_SNOMEDCT_US[1,4] / mean(rawdata_AncSPLRada_SNOMEDCT_US[2:6,5]), digits = 3)

table6[3,1] = "Lin";
# table6[3,2] = "IC-based";
table6[3,2] = round(rawdata_Lin_SNOMEDCT_US[1,2] / mean(rawdata_Lin_SNOMEDCT_US[2:6,3]), digits = 3)
table6[3,3] = round(rawdata_Lin_SNOMEDCT_US[1,6] / mean(rawdata_Lin_SNOMEDCT_US[2:6,7]), digits = 3)
table6[3,4] = round(rawdata_Lin_SNOMEDCT_US[1,4] / mean(rawdata_Lin_SNOMEDCT_US[2:6,5]), digits = 3)

table6[4,1] = "Wu-Palmer_fast";
# table6[4,2] = "depth-based";
table6[4,2] = round(rawdata_WuPalmer_SNOMEDCT_US[1,2] / mean(rawdata_WuPalmer_SNOMEDCT_US[2:6,3]), digits = 3)
table6[4,3] = "---";
table6[4,4] = round(rawdata_WuPalmer_SNOMEDCT_US[1,4] / mean(rawdata_WuPalmer_SNOMEDCT_US[2:6,5]), digits = 3)

# ------------------------------------------------------------------------
# Table 7 (in the paper), Experiment 2 in HESML_UMLS_benchmark.java: Average speed in concepts per second in the MeSH ontology
# ------------------------------------------------------------------------

caption_table7 = "Average speed in CUI concept pairs per second for the evaluation of random CUI pairs with three representative ontology-based similarity measures based on the MeSH ontology (Nov, 2019. 59747 nodes) implemented by the three UMLS-based semantic measures libraries reported in the literature. Best performing values are shown in bold. Non-implemented methods (---). \\hl{The number of random CUI pairs evaluated to measure each value is shown between parentheses.}"

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_Rada_MeSH <- read.csv(paste(inputDir, sep = "", "raw_output_Rada_MeSH.csv"), dec = ".", sep = ';')
rawdata_AncSPLRada_MeSH <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_MeSH.csv"), dec = ".", sep = ';')
rawdata_Lin_MeSH <- read.csv(paste(inputDir, sep = "", "raw_output_Lin_MeSH.csv"), dec = ".", sep = ';')
rawdata_WuPalmer_MeSH <- read.csv(paste(inputDir, sep = "", "raw_output_WuPalmerFast_MeSH.csv"), dec = ".", sep = ';')

# We create the table 2 as reported in the paper [4]

table7 <- matrix(nrow = 4, ncol = 4);

colnames(table7) <- c("Similarity measure", "UMLS::Sim", "SML", "HESML");

# We fill the row reporting the evaluation of the Rada measure

table7[1,1] = "Rada";
# table7[1,2] = "edge-counting";
table7[1,2] = round(rawdata_Rada_MeSH[1,2] / mean(rawdata_Rada_MeSH[2:6,3]), digits = 3)
table7[1,3] = round(rawdata_Rada_MeSH[1,6] / mean(rawdata_Rada_MeSH[2:6,7]), digits = 3)
table7[1,4] = round(rawdata_Rada_MeSH[1,4] / mean(rawdata_Rada_MeSH[2:6,5]), digits = 3)

table7[2,1] = "AnsSPLRada";
# table7[2,2] = "edge-counting";
table7[2,2] = "---";
table7[2,3] = "---";
table7[2,4] = round(rawdata_AncSPLRada_MeSH[1,4] / mean(rawdata_AncSPLRada_MeSH[2:6,5]), digits = 3)

table7[3,1] = "Lin";
# table7[3,2] = "IC-based";
table7[3,2] = round(rawdata_Lin_MeSH[1,2] / mean(rawdata_Lin_MeSH[2:6,3]), digits = 3)
table7[3,3] = round(rawdata_Lin_MeSH[1,6] / mean(rawdata_Lin_MeSH[2:6,7]), digits = 3)
table7[3,4] = round(rawdata_Lin_MeSH[1,4] / mean(rawdata_Lin_MeSH[2:6,5]), digits = 3)

table7[4,1] = "Wu-Palmer_fast";
# table7[4,2] = "depth-based";
table7[4,2] = round(rawdata_WuPalmer_MeSH[1,2] / mean(rawdata_WuPalmer_MeSH[2:6,3]), digits = 3)
table7[4,3] = "---";
table7[4,4] = round(rawdata_WuPalmer_MeSH[1,4] / mean(rawdata_WuPalmer_MeSH[2:6,5]), digits = 3)

# ------------------------------------------------------------------------
# Table 8 (in the paper), Experiment 3 in HESML_UMLS_benchmark.java: Average speed in GO concept pairs per second for the evaluation 
# of two representative ontology-based similarity measures based on the Gene Ontology
#
# ------------------------------------------------------------------------

caption_table8 = "Average speed in GO concept pairs per second for the evaluation of two representative ontology-based similarity measures based on the Gene Ontology \\cite{Ashburner2000-nu, The_Gene_Ontology_Consortium2019-hp} (2020-05-02 version) implemented by state-of-the-art SML \\cite{Harispe2014-cw} library and HESML. Best performing values are shown in bold.  \\hl{The number of random GO concept pairs evaluated to measure each value is shown between parentheses.}"

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_Rada_GO <- read.csv(paste(inputDir, sep = "", "raw_output_Rada_GO.csv"), dec = ".", sep = ';')
rawdata_AncSPLRada_GO <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_GO.csv"), dec = ".", sep = ';')
rawdata_Lin_GO <- read.csv(paste(inputDir, sep = "", "raw_output_Lin_GO.csv"), dec = ".", sep = ';')

# We create the table 1 as reported in the paper [4]

table8 <- matrix(nrow = 3, ncol = 4);

colnames(table8) <- c("Similarity measure", "Measure type", "SML", "HESML");

# We fill the row reporting the evaluation of the Rada measure

table8[1,1] = "Rada";
table8[1,2] = "edge-counting";
table8[1,3] = round(rawdata_Rada_GO[1,2] / mean(rawdata_Rada_GO[2:6,3]), digits = 3)
table8[1,4] = round(rawdata_Rada_GO[1,4] / mean(rawdata_Rada_GO[2:6,5]), digits = 3)

table8[2,1] = "AnsSPLRada";
table8[2,2] = "edge-counting";
table8[2,3] = "---";
table8[2,4] = round(rawdata_AncSPLRada_GO[1,4] / mean(rawdata_AncSPLRada_GO[2:6,5]), digits = 3)

table8[3,1] = "Lin";
table8[3,2] = "IC-based";
table8[3,3] = round(rawdata_Lin_GO[1,2] / mean(rawdata_Lin_GO[2:6,3]), digits = 3)
table8[3,4] = round(rawdata_Lin_GO[1,4] / mean(rawdata_Lin_GO[2:6,5]), digits = 3)


# ------------------------------------------------------------------------
# Table 9 (in the paper), Experiment 7 in HESML_UMLS_benchmark.java: Average speed in the evaluation of the semantic similarity
# between sentence pairs of the MedSTS [1] dataset with the the MeSH
# ontology and a collection of 1M of sentence pairs from the BioC corpus.
#
# [1] Y. Wang, N. Afzal, S. Fu, L. Wang, F. Shen, M. Rastegar-Mojarad, H. Liu,
# MedSTS: a resource for clinical semantic textual similarity,
# Language Resources and Evaluation. (2018) 1–16.
# ------------------------------------------------------------------------

caption_table9 = "Average speed in sentence pairs per second \\hl{(sent/secs) and CUI pairs per second (CUIs/secs)} for the evaluation of the UBSM \\cite{Sogancioglu2017-kb} sentence similarity measure combined with three representative ontology-based similarity measures based on MeSH (Nov, 2019) in \\hl{30} sentence pairs \\hl{extracted from} the MedSTS \\cite{Wang2018-oj} sentence similarity dataset, \\hl{and 1 million sentence pairs extracted from BioC corpus} \\cite{Comeau2019-ex}\\hl{. We provide the average evaluation in normalized CUI pairs per second to allow a fair and unbiased comparison of the results reported for 30 and 1 million sentence pairs. The dataset with 30 sentence pairs requires XXXX pairwise CUI comparisons, whilst the 1 million sentence pairs dataset requires YYY pairwise CUI comparisons.} Best performing values are shown in bold. Non-implemented methods (---)."

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_Rada_MedSTS <- read.csv(paste(inputDir, sep = "", "raw_output_Rada_MedSTS.csv"), dec = ".", sep = ';')
rawdata_AncSPLRada_MedSTS <- read.csv(paste(inputDir, sep = "", "raw_output_AncSPLRada_MedSTS.csv"), dec = ".", sep = ';')
rawdata_Lin_MedSTS <- read.csv(paste(inputDir, sep = "", "raw_output_Lin_MedSTS.csv"), dec = ".", sep = ';')
rawdata_WuPalmer_MedSTS <- read.csv(paste(inputDir, sep = "", "raw_output_WuPalmerFast_MedSTS.csv"), dec = ".", sep = ';')

# We create the table 4 as reported in the paper [4]

table9 <- matrix(nrow = 4, ncol = 9);

colnames(table9) <- c("Similarity measure", 
                      "\\makecell[c]{Avg. speed \\\\ (sent/sec)}", 
                      "\\makecell[c]{Avg. speed \\\\ (CUIs/sec)}", 
                      "\\makecell[c]{Avg. speed \\\\ (sent/sec)}", 
                      "\\makecell[c]{Avg. speed \\\\ (CUIs/sec)}",
                      "\\makecell[c]{Avg. speed \\\\ (sent/sec)}", 
                      "\\makecell[c]{Avg. speed \\\\ (CUIs/sec)}", 
                      "\\makecell[c]{Avg. speed \\\\ (sent/sec)}", 
                      "\\makecell[c]{Avg. speed \\\\ (CUIs/sec)}");

# SML library uses caching to store the similarity values. For this reason,
# we only consider the first value for a fair comparison.

# We fill the row reporting the evaluation of the Rada measure

table9[1,1] = "Rada";
# table9[1,2] = "edge-counting";

table9[1,2] = round(rawdata_Rada_MedSTS[6,2] / mean(rawdata_Rada_MedSTS[1:5,2]), digits = 3) # num_sent/mean(times)
table9[1,3] = round(rawdata_Rada_MedSTS[7,2] / mean(rawdata_Rada_MedSTS[1:5,2]), digits = 3) # num_cuis/mean(times)

table9[1,4] = round(rawdata_Rada_MedSTS[6,3] / mean(rawdata_Rada_MedSTS[1:5,3]), digits = 3)
table9[1,5] = round(rawdata_Rada_MedSTS[7,3] / mean(rawdata_Rada_MedSTS[1:5,3]), digits = 3)

table9[1,6] = round(rawdata_Rada_MedSTS[6,4] / mean(rawdata_Rada_MedSTS[1:5,4]), digits = 3)
table9[1,7] = round(rawdata_Rada_MedSTS[7,4] / mean(rawdata_Rada_MedSTS[1:5,4]), digits = 3)

table9[1,8] = round(rawdata_Rada_MedSTS[6,5] / mean(rawdata_Rada_MedSTS[1:5,5]), digits = 3)
table9[1,9] = round(rawdata_Rada_MedSTS[7,5] / mean(rawdata_Rada_MedSTS[1:5,5]), digits = 3)

table9[2,1] = "AnsSPLRada";
# table9[2,2] = "edge-counting";

table9[2,2] = "---";
table9[2,3] = "---";

table9[2,4] = "---";
table9[2,5] = "---";

table9[2,6] = round(rawdata_AncSPLRada_MedSTS[6,4] / mean(rawdata_AncSPLRada_MedSTS[1:5,4]), digits = 3)
table9[2,7] = round(rawdata_AncSPLRada_MedSTS[7,4] / mean(rawdata_AncSPLRada_MedSTS[1:5,4]), digits = 3)

table9[2,8] = round(rawdata_AncSPLRada_MedSTS[6,5] / mean(rawdata_AncSPLRada_MedSTS[1:5,5]), digits = 3)
table9[2,9] = round(rawdata_AncSPLRada_MedSTS[7,5] / mean(rawdata_AncSPLRada_MedSTS[1:5,5]), digits = 3)


table9[3,1] = "Lin";
# table9[3,2] = "IC-based";

table9[3,2] = round(rawdata_Lin_MedSTS[6,2] / mean(rawdata_Lin_MedSTS[1:5,2]), digits = 3)
table9[3,3] = round(rawdata_Lin_MedSTS[7,2] / mean(rawdata_Lin_MedSTS[1:5,2]), digits = 3)

table9[3,4] = round(rawdata_Lin_MedSTS[6,3] / mean(rawdata_Lin_MedSTS[1:5,3]), digits = 3)
table9[3,5] = round(rawdata_Lin_MedSTS[7,3] / mean(rawdata_Lin_MedSTS[1:5,3]), digits = 3)

table9[3,6] = round(rawdata_Lin_MedSTS[6,4] / mean(rawdata_Lin_MedSTS[1:5,4]), digits = 3)
table9[3,7] = round(rawdata_Lin_MedSTS[7,4] / mean(rawdata_Lin_MedSTS[1:5,4]), digits = 3)

table9[3,8] = round(rawdata_Lin_MedSTS[6,5] / mean(rawdata_Lin_MedSTS[1:5,5]), digits = 3)
table9[3,9] = round(rawdata_Lin_MedSTS[7,5] / mean(rawdata_Lin_MedSTS[1:5,5]), digits = 3)

table9[4,1] = "Wu-Palmer_fast";
# table9[4,2] = "depth-based";
table9[4,2] = round(rawdata_WuPalmer_MedSTS[6,2] / mean(rawdata_WuPalmer_MedSTS[1:5,2]), digits = 3)
table9[4,3] = round(rawdata_WuPalmer_MedSTS[7,2] / mean(rawdata_WuPalmer_MedSTS[1:5,2]), digits = 3)

table9[4,4] = "---";
table9[4,5] = "---";

table9[4,6] = round(rawdata_WuPalmer_MedSTS[6,4] / mean(rawdata_WuPalmer_MedSTS[1:5,4]), digits = 3)
table9[4,7] = round(rawdata_WuPalmer_MedSTS[7,4] / mean(rawdata_WuPalmer_MedSTS[1:5,4]), digits = 3)

table9[4,8] = round(rawdata_WuPalmer_MedSTS[6,5] / mean(rawdata_WuPalmer_MedSTS[1:5,5]), digits = 3)
table9[4,9] = round(rawdata_WuPalmer_MedSTS[7,5] / mean(rawdata_WuPalmer_MedSTS[1:5,5]), digits = 3)

# table9[5,1] = "Total CUI comparisons";
# table9[5,2] = rawdata_Rada_MedSTS[7,2];
# table9[5,3] = rawdata_AncSPLRada_MedSTS[7,3];
# table9[5,4] = rawdata_Lin_MedSTS[7,4];
# table9[5,5] = rawdata_WuPalmer_MedSTS[7,5];


# ------------------------------------------------------------------------
# Table 10 (in the paper), Experiment 4 in HESML_UMLS_benchmark.java: Pearson and Spearman correlation between base path-based measures
# and their AncSPL variant
# ------------------------------------------------------------------------


caption_table10 = "This table shows the Pearson \\hl{(r)} and Spearman \\hl{($\\rho$)} correlation values between the similarity values returned by a set of path-based similarity measures and those values returned by their reformulation based on the new AncSPL algorithm \\hl{for a sequence of 1000} random CUI pairs in SNOMED-CT 2019AB. \\hl{We show the results obtained in the evaluation of the first 50, 100, 200, and 1000 random CUI pairs}. All similarity measures are implemented in HESML V1R5 \\cite{Lastra-Diaz2020-xv}. CoswJ\\&C \\cite{Lastra-Diaz2015-ct} sets the current state-of-the-art in the family of ontology-based semantic similarity measures based on WordNet \\cite{Lastra-Diaz2019-kg}. \\hl{Note: the evaluation of any AncSPL-based measure in any tree-like taxonomy as MeSH will always report Pearson, and Spearman correlation metrics equal to 1, regardless of the number of CUI pairs, because AncSPL is exact in this case}."

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

rawdata_SNOMED_AncSPLRada_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_SNOMED_AncSPLRada_exp4.csv"), dec = ".", sep = ';')
rawdata_SNOMED_AncSPLLeacock_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_SNOMED_AncSPLLeacockChodorow_exp4.csv"), dec = ".", sep = ';')
rawdata_SNOMED_AncSPLCosine_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_SNOMED_AncSPLCosineNormWeightedJiangConrath_exp4.csv"), dec = ".", sep = ';')

rawdata_GO_AncSPLRada_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_GO_AncSPLRada_exp4.csv"), dec = ".", sep = ';')
rawdata_GO_AncSPLLeacock_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_GO_AncSPLLeacockChodorow_exp4.csv"), dec = ".", sep = ';')
rawdata_GO_AncSPLCosine_exp4 <- read.csv(paste(inputDir, sep = "", "raw_output_GO_AncSPLCosineNormWeightedJiangConrath_exp4.csv"), dec = ".", sep = ';')

# We create the table 5 as reported in the paper [4]

table10 <- matrix(nrow = 6, ncol = 10);

colnames(table10) <- c("Base measure", "AncSPL reformulation", "Pearson", "Spearman", "Pearson", "Spearman", "Pearson", "Spearman", "Pearson", "Spearman");

# We select the number of random rows to be used for each range of results

n_samples_1 <- 50
n_samples_2 <- 100
n_samples_3 <- 200
n_samples_4 <- 1000

# We select the sample tables for each part of the experiment 4

rawdata_SNOMED_AncSPLRada_exp4_sample_rows_1 <- head(rawdata_SNOMED_AncSPLRada_exp4,n_samples_1)
rawdata_SNOMED_AncSPLRada_exp4_sample_rows_2 <- head(rawdata_SNOMED_AncSPLRada_exp4,n_samples_2)
rawdata_SNOMED_AncSPLRada_exp4_sample_rows_3 <- head(rawdata_SNOMED_AncSPLRada_exp4,n_samples_3)
rawdata_SNOMED_AncSPLRada_exp4_sample_rows_4 <- head(rawdata_SNOMED_AncSPLRada_exp4,n_samples_4)

rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_1 <- head(rawdata_SNOMED_AncSPLLeacock_exp4,n_samples_1)
rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_2 <- head(rawdata_SNOMED_AncSPLLeacock_exp4,n_samples_2)
rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_3 <- head(rawdata_SNOMED_AncSPLLeacock_exp4,n_samples_3)
rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_4 <- head(rawdata_SNOMED_AncSPLLeacock_exp4,n_samples_4)

rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_1 <- head(rawdata_SNOMED_AncSPLCosine_exp4,n_samples_1)
rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_2 <- head(rawdata_SNOMED_AncSPLCosine_exp4,n_samples_2)
rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_3 <- head(rawdata_SNOMED_AncSPLCosine_exp4,n_samples_3)
rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_4 <- head(rawdata_SNOMED_AncSPLCosine_exp4,n_samples_4)

rawdata_GO_AncSPLRada_exp4_sample_rows_1 <- head(rawdata_GO_AncSPLRada_exp4,n_samples_1)
rawdata_GO_AncSPLRada_exp4_sample_rows_2 <- head(rawdata_GO_AncSPLRada_exp4,n_samples_2)
rawdata_GO_AncSPLRada_exp4_sample_rows_3 <- head(rawdata_GO_AncSPLRada_exp4,n_samples_3)
rawdata_GO_AncSPLRada_exp4_sample_rows_4 <- head(rawdata_GO_AncSPLRada_exp4,n_samples_4)

rawdata_GO_AncSPLLeacock_exp4_sample_rows_1 <- head(rawdata_GO_AncSPLLeacock_exp4,n_samples_1)
rawdata_GO_AncSPLLeacock_exp4_sample_rows_2 <- head(rawdata_GO_AncSPLLeacock_exp4,n_samples_2)
rawdata_GO_AncSPLLeacock_exp4_sample_rows_3 <- head(rawdata_GO_AncSPLLeacock_exp4,n_samples_3)
rawdata_GO_AncSPLLeacock_exp4_sample_rows_4 <- head(rawdata_GO_AncSPLLeacock_exp4,n_samples_4)

rawdata_GO_AncSPLCosine_exp4_sample_rows_1 <- head(rawdata_GO_AncSPLCosine_exp4,n_samples_1)
rawdata_GO_AncSPLCosine_exp4_sample_rows_2 <- head(rawdata_GO_AncSPLCosine_exp4,n_samples_2)
rawdata_GO_AncSPLCosine_exp4_sample_rows_3 <- head(rawdata_GO_AncSPLCosine_exp4,n_samples_3)
rawdata_GO_AncSPLCosine_exp4_sample_rows_4 <- head(rawdata_GO_AncSPLCosine_exp4,n_samples_4)

# We fill the row reporting the evaluation of the Rada measure


table10[1,1] = "Rada";
table10[1,2] = "AnsSPL-Rada";
table10[1,3] = round(cor(rawdata_SNOMED_AncSPLRada_exp4_sample_rows_1[,3], rawdata_SNOMED_AncSPLRada_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table10[1,4] = round(cor(rawdata_SNOMED_AncSPLRada_exp4_sample_rows_1[,3], rawdata_SNOMED_AncSPLRada_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table10[1,5] = round(cor(rawdata_SNOMED_AncSPLRada_exp4_sample_rows_2[,3], rawdata_SNOMED_AncSPLRada_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table10[1,6] = round(cor(rawdata_SNOMED_AncSPLRada_exp4_sample_rows_2[,3], rawdata_SNOMED_AncSPLRada_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table10[1,7] = round(cor(rawdata_SNOMED_AncSPLRada_exp4_sample_rows_3[,3], rawdata_SNOMED_AncSPLRada_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table10[1,8] = round(cor(rawdata_SNOMED_AncSPLRada_exp4_sample_rows_3[,3], rawdata_SNOMED_AncSPLRada_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table10[1,9] = round(cor(rawdata_SNOMED_AncSPLRada_exp4_sample_rows_4[,3], rawdata_SNOMED_AncSPLRada_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table10[1,10] = round(cor(rawdata_SNOMED_AncSPLRada_exp4_sample_rows_4[,3], rawdata_SNOMED_AncSPLRada_exp4_sample_rows_4[, 4], method = "spearman"), 4)

table10[2,1] = "Leacock-Chodorow";
table10[2,2] = "AnsSPL-Leacock";
table10[2,3] = round(cor(rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_1[,3], rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table10[2,4] = round(cor(rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_1[,3], rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table10[2,5] = round(cor(rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_2[,3], rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table10[2,6] = round(cor(rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_2[,3], rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table10[2,7] = round(cor(rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_3[,3], rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table10[2,8] = round(cor(rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_3[,3], rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table10[2,9] = round(cor(rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_4[,3], rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table10[2,10] = round(cor(rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_4[,3], rawdata_SNOMED_AncSPLLeacock_exp4_sample_rows_4[, 4], method = "spearman"), 4)

table10[3,1] = "coswJ&C";
table10[3,2] = "AnsSPL-coswJ&C";
table10[3,3] = round(cor(rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_1[,3], rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table10[3,4] = round(cor(rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_1[,3], rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table10[3,5] = round(cor(rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_2[,3], rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table10[3,6] = round(cor(rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_2[,3], rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table10[3,7] = round(cor(rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_3[,3], rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table10[3,8] = round(cor(rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_3[,3], rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table10[3,9] = round(cor(rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_4[,3], rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table10[3,10] = round(cor(rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_4[,3], rawdata_SNOMED_AncSPLCosine_exp4_sample_rows_4[, 4], method = "spearman"), 4)

table10[4,1] = "Rada";
table10[4,2] = "AnsSPL-Rada";
table10[4,3] = round(cor(rawdata_GO_AncSPLRada_exp4_sample_rows_1[,3], rawdata_GO_AncSPLRada_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table10[4,4] = round(cor(rawdata_GO_AncSPLRada_exp4_sample_rows_1[,3], rawdata_GO_AncSPLRada_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table10[4,5] = round(cor(rawdata_GO_AncSPLRada_exp4_sample_rows_2[,3], rawdata_GO_AncSPLRada_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table10[4,6] = round(cor(rawdata_GO_AncSPLRada_exp4_sample_rows_2[,3], rawdata_GO_AncSPLRada_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table10[4,7] = round(cor(rawdata_GO_AncSPLRada_exp4_sample_rows_3[,3], rawdata_GO_AncSPLRada_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table10[4,8] = round(cor(rawdata_GO_AncSPLRada_exp4_sample_rows_3[,3], rawdata_GO_AncSPLRada_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table10[4,9] = round(cor(rawdata_GO_AncSPLRada_exp4_sample_rows_4[,3], rawdata_GO_AncSPLRada_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table10[4,10] = round(cor(rawdata_GO_AncSPLRada_exp4_sample_rows_4[,3], rawdata_GO_AncSPLRada_exp4_sample_rows_4[, 4], method = "spearman"), 4)

table10[5,1] = "Leacock-Chodorow";
table10[5,2] = "AnsSPL-Leacock";
table10[5,3] = round(cor(rawdata_GO_AncSPLLeacock_exp4_sample_rows_1[,3], rawdata_GO_AncSPLLeacock_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table10[5,4] = round(cor(rawdata_GO_AncSPLLeacock_exp4_sample_rows_1[,3], rawdata_GO_AncSPLLeacock_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table10[5,5] = round(cor(rawdata_GO_AncSPLLeacock_exp4_sample_rows_2[,3], rawdata_GO_AncSPLLeacock_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table10[5,6] = round(cor(rawdata_GO_AncSPLLeacock_exp4_sample_rows_2[,3], rawdata_GO_AncSPLLeacock_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table10[5,7] = round(cor(rawdata_GO_AncSPLLeacock_exp4_sample_rows_3[,3], rawdata_GO_AncSPLLeacock_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table10[5,8] = round(cor(rawdata_GO_AncSPLLeacock_exp4_sample_rows_3[,3], rawdata_GO_AncSPLLeacock_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table10[5,9] = round(cor(rawdata_GO_AncSPLLeacock_exp4_sample_rows_4[,3], rawdata_GO_AncSPLLeacock_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table10[5,10] = round(cor(rawdata_GO_AncSPLLeacock_exp4_sample_rows_4[,3], rawdata_GO_AncSPLLeacock_exp4_sample_rows_4[, 4], method = "spearman"), 4)

table10[6,1] = "coswJ&C";
table10[6,2] = "AnsSPL-coswJ&C";
table10[6,3] = round(cor(rawdata_GO_AncSPLCosine_exp4_sample_rows_1[,3], rawdata_GO_AncSPLCosine_exp4_sample_rows_1[, 4], method = "pearson"), 4)
table10[6,4] = round(cor(rawdata_GO_AncSPLCosine_exp4_sample_rows_1[,3], rawdata_GO_AncSPLCosine_exp4_sample_rows_1[, 4], method = "spearman"), 4)
table10[6,5] = round(cor(rawdata_GO_AncSPLCosine_exp4_sample_rows_2[,3], rawdata_GO_AncSPLCosine_exp4_sample_rows_2[, 4], method = "pearson"), 4)
table10[6,6] = round(cor(rawdata_GO_AncSPLCosine_exp4_sample_rows_2[,3], rawdata_GO_AncSPLCosine_exp4_sample_rows_2[, 4], method = "spearman"), 4)
table10[6,7] = round(cor(rawdata_GO_AncSPLCosine_exp4_sample_rows_3[,3], rawdata_GO_AncSPLCosine_exp4_sample_rows_3[, 4], method = "pearson"), 4)
table10[6,8] = round(cor(rawdata_GO_AncSPLCosine_exp4_sample_rows_3[,3], rawdata_GO_AncSPLCosine_exp4_sample_rows_3[, 4], method = "spearman"), 4)
table10[6,9] = round(cor(rawdata_GO_AncSPLCosine_exp4_sample_rows_4[,3], rawdata_GO_AncSPLCosine_exp4_sample_rows_4[, 4], method = "pearson"), 4)
table10[6,10] = round(cor(rawdata_GO_AncSPLCosine_exp4_sample_rows_4[,3], rawdata_GO_AncSPLCosine_exp4_sample_rows_4[, 4], method = "spearman"), 4)


# ------------------------------------------------------------------------
# Table 11 (in the paper), Experiment 13 in HESML_UMLS_benchmark.java: comparison of two large GO annotated files describing
# the proteins of the Homo Sapiens and Mus  MUsculus organisms.
#
# ------------------------------------------------------------------------

caption_table11 = '\\hl{Overall running time in seconds and average speed in protein pairs per second obtained by four groupwise GO-based similarity measures (GO (44509 nodes), 2020-05-02 version) implemented by HESML in the evaluation of the pairwise protein similarity between the Homo Sapiens and Canis lupus familiaris organisms. We used the 542193 and 120720 GO annotations for both organisms provided by the ``goa\\_human.gaf" and ``go\\_dog.gaf" files, respectively. Approximately $340 \\times 10^6$ protein pairs and $33.5 \\times 10^9$ GO-annotation pairs are compared.}'

# Input raw CSV files generated by the reproducible experiments detailed
# in the supplementary appendix

raw_output_SimLP_largeGO <- read.csv(paste(inputDir, sep = "", "raw_output_SimLP_largeGO_test.csv"), dec = ".", sep = ';')
raw_output_SimUI_largeGO <- read.csv(paste(inputDir, sep = "", "raw_output_SimUI_largeGO_test.csv"), dec = ".", sep = ';')
raw_output_SimGIC_largeGO <- read.csv(paste(inputDir, sep = "", "raw_output_SimGIC_largeGO_test.csv"), dec = ".", sep = ';')
raw_output_BMA_Lin_Seco_largeGO <- read.csv(paste(inputDir, sep = "", "raw_output_BMA-Lin-Seco_largeGO_test.csv"), dec = ".", sep = ';')

# We create the table 1 as reported in the paper [4]

table11 <- matrix(nrow = 4, ncol = 4);

colnames(table11) <- c("", "", "", "");

# We fill the row reporting the evaluation of the Rada measure

table11[1,1] = "SimLP \\cite{Gentleman2009-dc}";
table11[1,2] = "\\makecell[l]{Common \\\\ ancestors \\\\ ratio}";
table11[1,3] = raw_output_SimLP_largeGO[1,4];
table11[1,4] = raw_output_SimLP_largeGO[1,2] / raw_output_SimLP_largeGO[1,4];

table11[2,1] = "SimUI \\cite{Gentleman2009-dc}";
table11[2,2] = "\\makecell[l]{Common \\\\ ancestor \\\\ max depth}";
table11[2,3] = raw_output_SimUI_largeGO[1,4];
table11[2,4] = raw_output_SimUI_largeGO[1,2] / raw_output_SimUI_largeGO[1,4];

table11[3,1] = "SimGIC-Seco \\cite{Pesquita2007-pv, Seco2004-fd}";
table11[3,2] = "IC-based";
table11[3,3] = raw_output_SimGIC_largeGO[1,4];
table11[3,4] = raw_output_SimGIC_largeGO[1,2] / raw_output_SimGIC_largeGO[1,4];

table11[4,1] = "BMA-Lin-Seco \\cite{Azuaje2005-cv, Lin1998-pm, Seco2004-fd}";
table11[4,2] = "IC-based";
table11[4,3] = raw_output_BMA_Lin_Seco_largeGO[1,4];
table11[4,4] = raw_output_BMA_Lin_Seco_largeGO[1,2] / raw_output_BMA_Lin_Seco_largeGO[1,4];

# ------------------------------------------------------------
# We save all final data tables 
# ------------------------------------------------------------

write.csv(table6, file = paste(outputDir, sep="","table6.csv"))
write.csv(table7, file = paste(outputDir, sep="","table7.csv"))
write.csv(table8, file = paste(outputDir, sep="","table8.csv"))
write.csv(table9, file = paste(outputDir, sep="","table9.csv"))
write.csv(table10, file = paste(outputDir, sep="","table10.csv"))
write.csv(table10, file = paste(outputDir, sep="","table11.csv"))
#-------------------------------
# HTML report generation
#-------------------------------

library(knitr)
library(readr)

# We load and browse Table 6 in the paper

kable_out <- kable(table6,
                   caption = caption_table6,
                   format = "html")

readr::write_file(kable_out, paste(outputDir, sep="","Table6.html"))
browseURL(paste(outputDir, sep="","Table6.html"))

# We load and browse Table 7 in the paper

kable_out <- kable(table7,
                   caption = caption_table7,
                   format = "html")

readr::write_file(kable_out, paste(outputDir, sep="","Table7.html"))
browseURL(paste(outputDir, sep="","Table7.html"))

# We load and browse Table 8 in the paper

kable_out <- kable(table8,
                   caption = caption_table8,
                   format = "html")

readr::write_file(kable_out, paste(outputDir, sep="","Table8.html"))
browseURL(paste(outputDir, sep="","Table8.html"))

# We load and browse Table 9 in the paper

kable_out <- kable(table9,
                   caption = caption_table9,
                   format = "html")

readr::write_file(kable_out, paste(outputDir, sep="","Table9.html"))
browseURL(paste(outputDir, sep="","Table9.html"))

# We load and browse Table 10 in the paper

kable_out <- kable(table10,
                   caption = caption_table10,
                   format = "html")

readr::write_file(kable_out, paste(outputDir, sep="","Table10.html"))
browseURL(paste(outputDir, sep="","Table10.html"))

kable_out <- kable(table11,
                   caption = caption_table11,
                   format = "html")

readr::write_file(kable_out, paste(outputDir, sep="","Table11.html"))
browseURL(paste(outputDir, sep="","Table11.html"))

#############################
# we export the latex tables
#############################

library(knitr)
library(readr)
library(kableExtra)
library(stringr)
library(xtable)


#############################
# Table 6
#############################

# We define the latex table with the data

colnames(table6) <- c("Similarity measure",
                      "\\makecell[c]{\\underline{UMLS::Sim} \\\\ Avg. speed \\\\ (pairs/sec)}",
                      "\\makecell[c]{\\underline{SML} \\\\ Avg. speed \\\\ (pairs/sec)}",
                      "\\makecell[c]{\\underline{HESML} \\\\ Avg. speed \\\\ (pairs/sec)}");

# Format the table modifying the fields

table6[1,1] = "Rada \\cite{Rada1989-cv}";
table6[2,1] = "\\makecell[l]{AncSPL-Rada \\\\ (this work)}";
table6[3,1] = "Lin-Seco \\cite{Lin1998-pm, Seco2004-fd}";
table6[4,1] = "Wu-Palmer$_{fast}$ \\cite{Wu1994-hh}";

table6[1,2] = paste0("\\hl{\\textbf{",table6[1,2],"}} (",rawdata_Rada_SNOMEDCT_US[1,2],")")
table6[1,4] = paste0("\\hl{",table6[1,4],"} (",rawdata_Rada_SNOMEDCT_US[1,4],")")

table6[2,4] = paste0("\\hl{\\textbf{",round(as.numeric(table6[2,4],decimal=0)),"}}",str_replace(rawdata_AncSPLRada_SNOMEDCT_US[1,4],"10000000","$(10^7)$"))

table6[3,2] = paste0("\\hl{",table6[3,2],"} (",rawdata_Lin_SNOMEDCT_US[1,2],")")
table6[3,3] = paste0("\\hl{",round(as.numeric(table6[3,3],decimal=0)),"}",str_replace(rawdata_Lin_SNOMEDCT_US[1,6],"10000000","$(10^7)$"))
table6[3,4] = paste0("\\hl{\\textbf{",round(as.numeric(table6[3,4],decimal=0)),"}}",str_replace(rawdata_Lin_SNOMEDCT_US[1,4],"10000000","$(10^7)$"))

table6[4,2] = paste0("\\hl{",table6[4,2],"} (",rawdata_WuPalmer_SNOMEDCT_US[1,2],")")
table6[4,4] = paste0("\\hl{\\textbf{",round(as.numeric(table6[4,4],decimal=0)),"}}",str_replace(rawdata_WuPalmer_SNOMEDCT_US[1,4],"10000000","$(10^7)$"))

table_latex <- xtable(table6, type = "latex", digits=4, method = "compact")

# We add extra rows to the table before printing it

addtorow      <- list()
addtorow$pos  <- list()

# We add an extra header with the dataset groups

addtorow$pos[[1]] <- -1
addtorow$command  <- c('')

# we define a function for adding \small to all rows.

add_small_to_all_rows.allrows <- function(x) {
  x
}

# We save the tables in latex and LATEX format files. 

output_dir_latex <- paste(outputDir, sep="","table6.txt")

strLatexTables <- print(xtable(table_latex, caption = caption_table6, label = "tab:snomed_results", digits=3, align ="llp{1.5cm}p{1.4cm}p{1.4cm}"), caption.placement = 'top',floating.environment = "table",
                        comment=FALSE, table.placement="h!", include.rownames=FALSE,
                        sanitize.colnames.function = identity, sanitize.text.function =  add_small_to_all_rows.allrows, file = output_dir_latex)

browseURL(paste(outputDir, sep="","table6.txt"))

#############################
# Table 7
#############################

# We define the latex table with the data

colnames(table7) <- c("Similarity measure",
                      "\\makecell[c]{\\underline{UMLS::Sim} \\\\ Avg. speed \\\\ (pairs/sec)}",
                      "\\makecell[c]{\\underline{SML} \\\\ Avg. speed \\\\ (pairs/sec)}",
                      "\\makecell[c]{\\underline{HESML} \\\\ Avg. speed \\\\ (pairs/sec)}");

# Format the table modifying the fields

table7[1,1] = "Rada \\cite{Rada1989-cv}";
table7[2,1] = "\\makecell[l]{AncSPL-Rada \\\\ (this work)}";
table7[3,1] = "Lin-Seco \\cite{Lin1998-pm, Seco2004-fd}";
table7[4,1] = "Wu-Palmer$_{fast}$ \\cite{Wu1994-hh}";

table7[1,2] = paste0("\\hl{",round(as.numeric(table7[1,2]),digits=2),"} (",rawdata_Rada_MeSH[1,2],")")
table7[1,3] = paste0("\\hl{",table7[1,3],"} (",rawdata_Rada_MeSH[1,6],")")
table7[1,4] = paste0("\\hl{\\textbf{",round(as.numeric(table7[1,4]),digits=0),"}}",str_replace(rawdata_Rada_MeSH[1,4],"10000000","$(10^7)$"))

table7[2,4] = paste0("\\hl{\\textbf{",round(as.numeric(table7[2,4]),digits=0),"}}",str_replace(rawdata_AncSPLRada_MeSH[1,4],"10000000","$(10^7)$"))

table7[3,2] = paste0("\\hl{",round(as.numeric(table7[3,2]),digits=2),"} (",rawdata_Lin_MeSH[1,2],")")
table7[3,3] = paste0("\\hl{",round(as.numeric(table7[3,3]),digits=0),"}",str_replace(rawdata_Lin_MeSH[1,6],"10000000","$(10^7)$"))
table7[3,4] = paste0("\\hl{\\textbf{",round(as.numeric(table7[3,4]),digits=0),"}}",str_replace(rawdata_Lin_MeSH[1,4],"10000000","$(10^7)$"))

table7[4,2] = paste0("\\hl{",round(as.numeric(table7[4,2]),digits=2),"} (",rawdata_WuPalmer_MeSH[1,2],")")
table7[4,4] = paste0("\\hl{\\textbf{",round(as.numeric(table7[4,4]),digits=0),"}}",str_replace(rawdata_WuPalmer_MeSH[1,4],"10000000","$(10^7)$"))

table_latex <- xtable(table7, type = "latex", digits=4, method = "compact")

# We add extra rows to the table before printing it

addtorow      <- list()
addtorow$pos  <- list()

# We add an extra header with the dataset groups

addtorow$pos[[1]] <- -1
addtorow$command  <- c('')

# we define a function for adding \small to all rows.

add_small_to_all_rows.allrows <- function(x) {
  x
}

# We save the tables in latex and LATEX format files. 

output_dir_latex <- paste(outputDir, sep="","table7.txt")

strLatexTables <- print(xtable(table_latex, caption = caption_table7, label = "tab:mesh_results", digits=3, align ="llp{1.6cm}p{1.4cm}p{1.5cm}"), caption.placement = 'top',floating.environment = "table",
                        comment=FALSE, table.placement="h!", include.rownames=FALSE,
                        sanitize.colnames.function = identity, sanitize.text.function =  add_small_to_all_rows.allrows, file = output_dir_latex)

browseURL(paste(outputDir, sep="","table7.txt"))

#############################
# Table 8
#############################

# We define the latex table with the data

colnames(table8) <- c("Similarity measure","Measure type",
                      "\\makecell[c]{Avg. speed \\\\ (pairs/sec)}",
                      "\\makecell[c]{Avg. speed \\\\ (pairs/sec)}");

# Format the table modifying the fields

table8[1,1] = "Rada \\cite{Rada1989-cv}";
table8[2,1] = "\\makecell[l]{AncSPL-Rada \\\\ (this work)}";
table8[3,1] = "\\makecell[l]{Lin-Seco \\cite{Lin1998-pm, Seco2004-fd} \\\\ IC model}";

table8[1,3] = paste0("\\hl{",table8[1,3],"} (",rawdata_Rada_GO[1,2],")")
table8[1,4] = paste0("\\hl{\\textbf{",table8[1,4],"}} (",rawdata_Rada_GO[1,4],")")

table8[2,4] = paste0("\\hl{\\textbf{",round(as.numeric(table8[2,4]),digits=0),"}}",str_replace(rawdata_AncSPLRada_GO[1,4],"10000000","$(10^7)$"))

table8[3,3] = paste0("\\hl{",round(as.numeric(table8[3,3]),digits=0),"}",str_replace(rawdata_Lin_GO[1,4],"10000000","$(10^7)$"))
table8[3,4] = paste0("\\hl{\\textbf{",round(as.numeric(table8[3,4]),digits=0),"}}",str_replace(rawdata_Lin_GO[1,4],"10000000","$(10^7)$"))

table_latex <- xtable(table8, type = "latex", digits=4, method = "compact")

# We add extra rows to the table before printing it

addtorow      <- list()
addtorow$pos  <- list()

# We add an extra header with the dataset groups

addtorow$pos[[1]] <- -1
addtorow$command  <- c('\\hline \\multicolumn{2}{l}{\\makecell[l]{Evaluation of random concept \\\\ pairs using GO (\\hl{44509} nodes)}} & \\underline{SML}  & \\underline{HESML} \\\\')

# we define a function for adding \small to all rows.

add_small_to_all_rows.allrows <- function(x) {
  x
}

# We save the tables in latex and LATEX format files. 

output_dir_latex <- paste(outputDir, sep="","table8.txt")

strLatexTables <- print(xtable(table_latex, caption = caption_table8, label = "tab:go_results", digits=3, align ="llp{1.4cm}p{1.4cm}p{1.5cm}"), caption.placement = 'top',floating.environment = "table",
                        comment=FALSE, table.placement="h!", include.rownames=FALSE,add.to.row = addtorow,
                        sanitize.colnames.function = identity, sanitize.text.function =  add_small_to_all_rows.allrows, file = output_dir_latex)

browseURL(paste(outputDir, sep="","table8.txt"))

#############################
# Table 9
#############################

# We define the latex table with the data

table9_b <- table9

# colnames(table9) <- c("Similarity measure", "\\makecell[c]{Avg. speed \\\\ (sent/sec)}", "\\makecell[c]{Avg. speed \\\\ (CUIs/sec)}", "\\makecell[c]{Avg. speed \\\\ (sent/sec)}", "\\makecell[c]{Avg. speed \\\\ (CUIs/sec)}", "\\makecell[c]{Avg. speed \\\\ (sent/sec)}", "\\makecell[c]{Avg. speed \\\\ (CUIs/sec)}", "\\makecell[c]{Avg. speed \\\\ (sent/sec)}", "\\makecell[c]{Avg. speed \\\\ (CUIs/sec)}");

table9[1,1] = "Rada et al. \\cite{Rada1989-cv}";
table9[2,1] = "\\makecell[l]{AncSPL-Rada \\\\ (this work)}";
table9[3,1] = "Lin-Seco \\cite{Lin1998-pm, Seco2004-fd}";
table9[4,1] = "Wu-Palmer$_{fast}$\\cite{Wu1994-hh}";

table9[1,6] = paste0("\\textbf{",table9[1,6],"}");
table9[2,6] = paste0("\\textbf{",table9[2,6],"}");
table9[3,6] = paste0("\\textbf{",table9[3,6],"}");
table9[4,6] = paste0("\\textbf{",table9[4,6],"}");
table9[3,4] = paste0("\\textbf{",table9[3,4],"}");


table_latex <- xtable(table9, type = "latex", digits=4, method = "compact")

# We add extra rows to the table before printing it

addtorow      <- list()
addtorow$pos  <- list()

# We add an extra header with the dataset groups

addtorow$pos[[1]] <- -1
addtorow$command  <- c(
  '\\hline \\makecell[l]{Pairwise sentence \\\\ comparison based \\\\ on MeSH} & \\multicolumn{2}{c}{\\underline{UMLS::Sim (30 pairs)}} & \\multicolumn{2}{c}{\\underline{SML (30 pairs)}} & \\multicolumn{2}{c}{\\underline{HESML (30 pairs)}} & \\multicolumn{2}{c}{\\underline{HESML ($10^6$ pairs)}} \\\\ ')



# we define a function for adding \small to all rows.

add_small_to_all_rows.allrows <- function(x) {
  x # this function returns the same input value, only for tests
}

#add_small_to_all_rows.allrows <- function(x) {
#  h <- paste('\\small{',x,'}', sep ='')
#  h
#}

# We align the table

align(table_latex) <- "llcccccccc"

# We save the tables in latex and LATEX format files. 

output_dir_latex <- paste(outputDir, sep="","table9.txt")

strLatexTables <- print(xtable(table_latex, caption = caption_table9, label = "tab:medsts_results", digits=3), caption.placement = 'top',floating.environment = "table*",
                        add.to.row = addtorow, comment=FALSE, table.placement="h!", include.rownames=FALSE,
                        sanitize.colnames.function = identity, sanitize.text.function =  add_small_to_all_rows.allrows, file = output_dir_latex)

browseURL(paste(outputDir, sep="","table9.txt"))


#############################
# Table 10
#############################

# We define the latex table with the data

colnames(table10) <- c("Base measure", "\\makecell[c]{AncSPL \\\\ reformulation}", "r", '$\\rho$', "r", '$\\rho$', "r", '$\\rho$', "r", '$\\rho$');

table10[1,1] = "Rada \\cite{Rada1989-cv}";
table10[2,1] = "\\makecell[l]{Leacock and \\\\ Chodorow \\cite{Leacock1998-hr}}";
table10[3,1] = "coswJ\\&C \\cite{Lastra-Diaz2015-ct}";
table10[3,2] = "AnsSPL-coswJ\\&C";

table10[4,1] = "Rada \\cite{Rada1989-cv}";
table10[5,1] = "\\makecell[l]{Leacock and \\\\ Chodorow \\cite{Leacock1998-hr}}";
table10[6,1] = "coswJ\\&C \\cite{Lastra-Diaz2015-ct}";
table10[6,2] = "AnsSPL-coswJ\\&C";


table_latex <- xtable(table10, type = "latex", digits=4, method = "compact")

# We add extra rows to the table before printing it

addtorow      <- list()
addtorow$pos  <- list()

# We add an extra header with the dataset groups

addtorow$pos[[1]] <- -1
addtorow$pos[[2]] <- 3
addtorow$pos[[3]] <- 3
addtorow$command  <- c(
  '\\hline \\multicolumn{2}{l}{\\hl{Correlation values in SNOMED-CT}} & \\multicolumn{2}{c}{\\underline{50 samples}} & \\multicolumn{2}{c}{\\underline{100 samples}} & \\multicolumn{2}{c}{\\underline{200 samples}} & \\multicolumn{2}{c}{\\underline{1000 samples}} \\\\ ',
  '\\hline \\multicolumn{2}{l}{\\hl{Correlation values in GO}} & \\multicolumn{2}{c}{\\underline{50 samples}} & \\multicolumn{2}{c}{\\underline{100 samples}} & \\multicolumn{2}{c}{\\underline{200 samples}} & \\multicolumn{2}{c}{\\underline{1000 samples}} \\\\ ',
  'Base measure & \\makecell[c]{AncSPL \\\\ reformulation} & r & $\\rho$ & r & $\\rho$ & r & $\\rho$ & r & $\\rho$ \\\\ \\hline ')



# we define a function for adding \small to all rows.

add_small_to_all_rows.allrows <- function(x) {
  x # this function returns the same input value, only for tests
}

#add_small_to_all_rows.allrows <- function(x) {
#  h <- paste('\\small{',x,'}', sep ='')
#  h
#}

# We align the table

align(table_latex) <- "llccccccccc"

# We save the tables in latex and LATEX format files. 

output_dir_latex <- paste(outputDir, sep="","table10.txt")

strLatexTables <- print(xtable(table_latex, caption = caption_table10, label = "tab:ancspl_results", digits=3), caption.placement = 'top',floating.environment = "table*",
                        add.to.row = addtorow, comment=FALSE, table.placement="h!", include.rownames=FALSE,
                        sanitize.colnames.function = identity, sanitize.text.function =  add_small_to_all_rows.allrows, file = output_dir_latex)

browseURL(paste(outputDir, sep="","table10.txt"))


#############################
# Table 11
#############################

# We define the latex table with the data

colnames(table11) <- c("Groupwise measure", "Measure type", "\\makecell[c]{\\underline{HESML} \\\\ Time (secs)}", "\\makecell[l]{Avg. speed \\\\ (prot. pairs/sec)}");

table11[3,1] = "\\makecell[l]{SimGIC-Seco \\\\ \\cite{Pesquita2007-pv, Seco2004-fd}}";
table11[4,1] = "\\makecell[l]{BMA-Lin-Seco \\\\ \\cite{Azuaje2005-cv, Lin1998-pm, Seco2004-fd}}";

table11[1,4] = round(as.numeric(table11[1,4]),digits=0)
table11[2,4] = round(as.numeric(table11[2,4]),digits=0)
table11[3,4] = round(as.numeric(table11[3,4]),digits=0)
table11[4,4] = round(as.numeric(table11[4,4]),digits=0)

table11[1,3] = round(as.numeric(table11[1,3]),digits=0)
table11[2,3] = round(as.numeric(table11[2,3]),digits=0)
table11[3,3] = round(as.numeric(table11[3,3]),digits=0)
table11[4,3] = round(as.numeric(table11[4,3]),digits=0)

table_latex <- xtable(table11, type = "latex", digits=4, method = "compact")

# We add extra rows to the table before printing it

addtorow      <- list()
addtorow$pos  <- list()

# We add an extra header with the dataset groups

addtorow$pos[[1]] <- -1
addtorow$command  <- c(
  ' \\hline \\multicolumn{4}{l}{Pairwise protein comparison between two large organisms} \\\\ ')



# we define a function for adding \small to all rows.

add_small_to_all_rows.allrows <- function(x) {
  x # this function returns the same input value, only for tests
}

# We align the table

align(table_latex) <- "lllcc"

# We save the tables in latex and LATEX format files. 

output_dir_latex <- paste(outputDir, sep="","table11.txt")

strLatexTables <- print(xtable(table_latex, caption = caption_table11, label = "tab:large_go_results", digits=3), caption.placement = 'top',floating.environment = "table",
                        add.to.row = addtorow, comment=FALSE, table.placement="h!", include.rownames=FALSE,
                        sanitize.colnames.function = identity, sanitize.text.function =  add_small_to_all_rows.allrows, file = output_dir_latex)

browseURL(paste(outputDir, sep="","table11.txt"))


#############################
# Figures 2 and 3
#############################

# We load the library

library(EnvStats)

# We load the data

raw_SNOMED_AnsSPL_subgraph_groups <- read.csv(paste(inputDir, sep = "", "raw_SNOMED_AnsSPL_subgraph_groups.csv"), sep=';', dec='.');
raw_GO_AnsSPL_subgraph_groups <- read.csv(paste(inputDir, sep = "", "raw_GO_AnsSPL_subgraph_groups.csv"), sep=';', dec='.');

# We define a variable with the available ontologies for the experiment

ontologies <- c("SNOMED", "GO")
  
# We extract the columns information 

distances <- list(raw_SNOMED_AnsSPL_subgraph_groups[,1], raw_GO_AnsSPL_subgraph_groups[,1])
pairs <- list(raw_SNOMED_AnsSPL_subgraph_groups[,2], raw_GO_AnsSPL_subgraph_groups[,2])
overall_speeds <- list(raw_SNOMED_AnsSPL_subgraph_groups[,3], raw_GO_AnsSPL_subgraph_groups[,3])
average_speeds <- list(raw_SNOMED_AnsSPL_subgraph_groups[,4], raw_GO_AnsSPL_subgraph_groups[,4])

# We create a counter

counter <- 1

# We create the figures for each type of experiment

for (ontology in ontologies) 
{
    # We calculate the average speeds in microseconds (*10e6)
  
    average_speeds[[counter]] = lapply(average_speeds[[counter]], function(x) x*1000000)
    
    # We plot the average speed / distance
    
    setEPS()
    postscript(paste(outputDir, "figure_", ontology, "_average_scal.eps", sep=""))
    plot(distances[[counter]], average_speeds[[counter]], type="l", lwd=1,
         ylab="Average running time of AncSPL (microseconds)",
         xlab="Dimension of the ancestor-based subgraph in the shortest-path computation",
         main="AncSPL running time regarding the dimension of the subgraph.")
    
    grid(NULL,NULL,lty=6)
    dev.off()
    
    counter <- counter + 1
}

#############################
# Figures 4 and 5
#############################

# We load the data

raw_AnsSPL_SNOMED_statisticalData <- read.csv(paste(inputDir, sep = "", "raw_AnsSPL_SNOMED_statisticalData_test.csv"), sep=';', dec='.');
raw_AnsSPL_GO_statisticalData <- read.csv(paste(inputDir, sep = "", "raw_AnsSPL_GO_statisticalData_test.csv"), sep=';', dec='.');

# We compute the AncSPL distance error function

error_SNOMED <- raw_AnsSPL_SNOMED_statisticalData[,4]-raw_AnsSPL_SNOMED_statisticalData[,3];
error_GO <- raw_AnsSPL_GO_statisticalData[,4]-raw_AnsSPL_GO_statisticalData[,3];

# We plot the Empirical Cumulative Distribution Function
# and save it into a EPS file

setEPS()
postscript(paste(outputDir, sep="","figure_SNOMED_stat.eps"))

ecdfPlot(error_SNOMED, discrete=TRUE, axes=FALSE,
         xlab="Signed AncSPL length error in number of edges (1000 random samples)",
         main="Cumulative Distribution Function for the AncSPL error in SNOMED-CT")

axis(side = 1,at = 0:max(error_SNOMED))
axis(side = 2,at = c(0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0))
grid(NULL,NULL,lty=6)
dev.off()


setEPS()
postscript(paste(outputDir, sep="","figure_GO_stat.eps"))

ecdfPlot(error_GO, discrete=TRUE, axes=FALSE,
         xlab="Signed AncSPL length error in number of edges (1000 random samples)",
         main="Cumulative Distribution Function for the AncSPL error in GO")

axis(side = 1,at = 0:max(error_GO))
axis(side = 2,at = c(0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0))
grid(NULL,NULL,lty=6)
dev.off()

