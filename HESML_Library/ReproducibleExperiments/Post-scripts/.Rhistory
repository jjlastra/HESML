# semantic measure for each sentence pair.
# First column contains the uman judgements for each sentence pair
# whilst subsequent columns contain the values returned by the
# sentence similaritu measures.
# ---------------------------------------------------------------------
# ---------------------------------------------------------------------
# Table 1: Pearson and Spearman metrics of all sentence similarity
# measures.
# ---------------------------------------------------------------------
# We define all datasets represented in table 1
rawdata_allDatasets <- list(rawdata_BIOSSES, rawdata_MedSTS, rawdata_CTR)
# We create a separated table for each metric by removing the first column
# which contains the human judgements. Measures are arranged in rows
# whilst datasets are arranged in columns.
table_Pearson <- matrix(nrow = ncol(rawdata_BIOSSES) - 1,
ncol = length(rawdata_allDatasets),
dimnames = list(colnames(rawdata_BIOSSES)[2:ncol(rawdata_BIOSSES)],
c("BIOSSES", "MedSTS", "CTR")))
table_Spearman <- table_Pearson
table_Harmonic <- table_Pearson
# Loop for the computation of the metrics
nMeasures <- nrow(table_Pearson)
nDatasets <- length(rawdata_allDatasets)
for (iDataset in 1:nDatasets)
{
# We get the raw data of the next dataset
rawdata <- rawdata_allDatasets[[iDataset]]
# We evaluate the Pearson and Spearman metrics for each measure in the current dataset
for (iMeasure in 1:nMeasures)
{
rawdata[,1]
rawdata[, iMeasure + 1]
table_Pearson[iMeasure, iDataset] <- cor(rawdata[,1], rawdata[, iMeasure + 1], use="complete.obs", method = "pearson")
table_Spearman[iMeasure, iDataset] <- cor(rawdata[,1], rawdata[, iMeasure + 1], use="complete.obs", method = "spearman")
table_Harmonic[iMeasure, iDataset] <- 2 * table_Pearson[iMeasure, iDataset] * table_Spearman[iMeasure, iDataset] / (table_Pearson[iMeasure, iDataset] + table_Spearman[iMeasure, iDataset])
}
}
# ------------------------------------------------------------
# We merge all metrics (Pearson, Spearman and Harmonic score)
# into a same data table by concatening previouos data tables.
# ------------------------------------------------------------
table_allMetrics <- cbind(table_Pearson, table_Spearman, table_Harmonic, Avg = rowMeans(table_Harmonic[1:nrow(table_Harmonic),]))
# table_allMetrics <- cbind(table_Pearson, table_Spearman, Avg = rowMeans(table_Harmonic[1:nrow(table_Harmonic),]))
table_allMetrics <- mat.sort(table_allMetrics, ncol(table_allMetrics), decreasing = TRUE)
# We set the column names to the final matrix
colnames(table_allMetrics) <- c("r", "r", "r",
'$\\rho$', '$\\rho$', '$\\rho$',
"h", "h", "h",
"Avg")
# colnames(table_allMetrics) <- c("r", "r", "r",
#                                 '$\\rho$', '$\\rho$', '$\\rho$',
#                                 "Avg")
# We reorder the matrix columns grouping by dataset names.
table_allMetrics <- table_allMetrics[ , c(1,4,7,2,5,8,3,6,9,10) ]
# table_allMetrics <- table_allMetrics[ , c(1,4,2,5,3,6,7) ]
# We make a copy of the tables in order to round their values to 3 decimal digits
table_allMetrics_rounded <- round(table_allMetrics, 3);
table_allMetrics_rounded <- as.data.frame(table_allMetrics_rounded)
table_allMetrics_rounded
# We save all final assembled data tables
write.csv(table_allMetrics, file = paste(outputDir,"table_allMetrics_", experimentLabel, ".csv", sep=""))
write.csv(table_allMetrics_rounded, file = paste(outputDir, "table_allMetrics_rounded_", experimentLabel, ".csv", sep=""))
# We add the output table to the Latex dictionary
latexTables$set(strCaption, table_allMetrics_rounded)
#-------------------------------
# LATEX report generation
#
# IMPORTANT NOTE: To avoid the problem of oversizing the box, add manually the next command BEFORE tabular:
#
# \resizebox{\columnwidth}{!}{%
#
# TABLE DATA
#
# }
# \end{table}
#-------------------------------
library(knitr)
library(readr)
library(kableExtra)
library(stringr)
library(xtable)
# We define the latex table with the data
table_latex <- xtable(table_allMetrics_rounded, type = "latex", digits=4, method = "compact")
# We add extra rows to the table before printing it
addtorow      <- list()
addtorow$pos  <- list()
# We add an extra header with the dataset groups
addtorow$pos[[1]] <- -1
addtorow$command  <- c('\\hline \\multicolumn{1}{c}{ } & \\multicolumn{3}{c}{BIOSSES} & \\multicolumn{3}{c}{MedSTS} & \\multicolumn{3}{c}{CTR} & \\multicolumn{1}{c}{Avg} \\\\ ')
tableLatex <- print(xtable(table_latex, caption = strCaption, digits=3), caption.placement = 'top',
add.to.row = addtorow, comment=FALSE, size="\\tiny", table.placement="!h", sanitize.colnames.function = identity)
# We save the tables in latex and HTML format files. The HTML format is for
strLatexTables <- paste(strLatexTables, sep="\n\n", tableLatex)
# Write the Latex table in a file
file_name <- paste(outputDir,"table_", experimentLabel, ".txt", sep="")
write_file(tableLatex, file_name)
# And open the table in the default file browser.
# browseURL(file_name)
}
# Write the Latex table in a file
file_name <- paste(outputDir,"table_allMetricsALLJoint.txt", sep="")
write_file(strLatexTables, file_name)
browseURL(file_name)
counter_executions
# Description:
#
# This script loads a collection of sentence similarity benchmarks generated
# by HESMLSTSclient program, which contain the raw similarity values for
# sentence pair. Then, the script computes a collection of consolidated tables
# including the Pearson, Spearman and harmonic score metrics.
#
# References:
# ----------
# We clear all session variables
rm(list = ls())
# IMPORTANT:configuration of the input/output directories
# We define below the input directory for the input raw results
# in CSV file format, and the output directory for the
# final assembled tables in CSV file format.
# You must change these values in order to
# point to the proper directories in your hard drive.
# We also define below the name of the input raw CSV files
# containing the experimental results.
# The input and output directories below must end with '/' in
# Unix-like format to be compatible with Windows
# or Linux-based R distributions.
# First, we get the current file script directory
current_working_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
# and we set the working directory for the R project
setwd(current_working_dir)
# Define the root path
rootDir = "../BioSentenceSimilarity_paper"
# We import the library that implements the data structures.
library(collections)
# We create an OrderedDict object with all the experiments that will be evaluated.
experiments <- ordered_dict()
# We define the subdirectory experiment and the caption for showing the results in Latex and HTML format
# and we add to the dictionary all the String-based measures experiments
experimentSubdirectory = "BioSentenceSimFinalRawOutputFiles"
preprocessedExperimentsSubdirectory = "BioSentenceSimFinalProcessedOutputFiles"
# We create a Dictionary object for printing the Latex tables with the captions
latexTables <- ordered_dict()
# We define the output directory
dir.create(paste(rootDir, "/", preprocessedExperimentsSubdirectory, "/", sep = ""))
outputDir =  paste(rootDir, "/", preprocessedExperimentsSubdirectory, "/", sep = "")
# We create a list for each output table
rawdata_experiments <- list()
# Input raw CSV files generated by the reproducible experiments detailed
# in the companion paper for each sentence similarity dataset
# We define the input datasets directories
inputDir = paste(rootDir, "/", experimentSubdirectory, "/", sep = "")
# We load the input raw results file for string-based measures
source(paste("bio_sentence_sim_scripts", "readString.R", sep = "/"), local = knitr::knit_global())
# We load the input raw results file for OurWE-based measures
source(paste("bio_sentence_sim_scripts", "readOurWE.R", sep = "/"), local = knitr::knit_global())
# We load the input raw results file for SWEM-based measures
source(paste("bio_sentence_sim_scripts", "readSWEM.R", sep = "/"), local = knitr::knit_global())
# We load the input raw results file for WBSM-based measures
source(paste("bio_sentence_sim_scripts", "readWBSM.R", sep = "/"), local = knitr::knit_global())
# We load the input raw results file for UBSM-based measures
source(paste("bio_sentence_sim_scripts", "readUBSM.R", sep = "/"), local = knitr::knit_global())
# We load the input raw results file for COM-based measures
source(paste("bio_sentence_sim_scripts", "readCOM.R", sep = "/"), local = knitr::knit_global())
# We load the input raw results file for COMMixed-based measures
source(paste("bio_sentence_sim_scripts", "readCOMMixed.R", sep = "/"), local = knitr::knit_global())
# We load the input raw results file for Sent2Vec-based measures
source(paste("bio_sentence_sim_scripts", "readBERT.R", sep = "/"), local = knitr::knit_global())
# We load the input raw results file for Sent2Vec-based measures
source(paste("bio_sentence_sim_scripts", "readSent2Vec.R", sep = "/"), local = knitr::knit_global())
# We load the input raw results file for Sent2Vec-based measures
source(paste("bio_sentence_sim_scripts", "readUSE.R", sep = "/"), local = knitr::knit_global())
# We load the input raw results file for Sent2Vec-based measures
source(paste("bio_sentence_sim_scripts", "readFlair.R", sep = "/"), local = knitr::knit_global())
# We load the input raw results file for best combinations (FINAL RESULTS)
source(paste("bio_sentence_sim_scripts", "readBESTCOMBS.R", sep = "/"), local = knitr::knit_global())
# We load the input raw results file forNER experiments (FINAL RESULTS)
source(paste("bio_sentence_sim_scripts", "readNERexperiment.R", sep = "/"), local = knitr::knit_global())
# We add the experiments to the list
# rawdata_experiments <- list(rawdata_string, rawdata_OurWE, rawdata_WBSM, rawdata_UBSM, rawdata_COM, rawdata_SWEM, rawdata_Sent2Vec, rawdata_USE, rawdata_Flair, rawdata_BERT, rawdata_NERexperiment)
rawdata_experiments <- list(rawdata_BESTCOMBS)
# rawdata_experiments <- list(rawdata_NERexperiment)
# We initialize the counter of executions
counter_executions <- 0
# We initialize the string with the latex tables output. We will print all at the end of the script
strLatexTables <- ""
# Loop for the defined experiments and calculate the scores for Pearson, Sperman and Harmonic.
for(iexperiment in rawdata_experiments)
{
# We get the label
experimentLabel = iexperiment$label
# We update the counter with the number of columns (the number the experiments that are in the table)
counter_executions <- counter_executions + ncol(iexperiment$biosses) - 1
# We get the experiment subdirectory and the caption for the Latex File
strCaption = paste("Table \\label{table:", experimentSubdirectory, "}: Pearson (r), Spearman ($\rho$) and Harmonic score (h) obtained by the ", experimentLabel, " similarity methods evaluated herein.", sep="")
rawdata_BIOSSES <- iexperiment$biosses
rawdata_MedSTS  <- iexperiment$medsts
rawdata_CTR     <- iexperiment$ctr
# mat.sort function is copied from source files of
# BioPhysConnectoR package which is now unavailable.
# Source code was retrieved from https://rdrr.io/cran/BioPhysConnectoR/src/R/mat.sort.r
mat.sort<-function(mat,sort,decreasing=FALSE)
{
m<-do.call("order",c(as.data.frame(mat[,sort]),decreasing=decreasing))
mat[m,]
}
# ---------------------------------------------------------------------
# Raw output file format:
# Raw similarity files contain the similarity values returned by each
# semantic measure for each sentence pair.
# First column contains the uman judgements for each sentence pair
# whilst subsequent columns contain the values returned by the
# sentence similaritu measures.
# ---------------------------------------------------------------------
# ---------------------------------------------------------------------
# Table 1: Pearson and Spearman metrics of all sentence similarity
# measures.
# ---------------------------------------------------------------------
# We define all datasets represented in table 1
rawdata_allDatasets <- list(rawdata_BIOSSES, rawdata_MedSTS, rawdata_CTR)
# We create a separated table for each metric by removing the first column
# which contains the human judgements. Measures are arranged in rows
# whilst datasets are arranged in columns.
table_Pearson <- matrix(nrow = ncol(rawdata_BIOSSES) - 1,
ncol = length(rawdata_allDatasets),
dimnames = list(colnames(rawdata_BIOSSES)[2:ncol(rawdata_BIOSSES)],
c("BIOSSES", "MedSTS", "CTR")))
table_Spearman <- table_Pearson
table_Harmonic <- table_Pearson
# Loop for the computation of the metrics
nMeasures <- nrow(table_Pearson)
nDatasets <- length(rawdata_allDatasets)
for (iDataset in 1:nDatasets)
{
# We get the raw data of the next dataset
rawdata <- rawdata_allDatasets[[iDataset]]
# We evaluate the Pearson and Spearman metrics for each measure in the current dataset
for (iMeasure in 1:nMeasures)
{
rawdata[,1]
rawdata[, iMeasure + 1]
table_Pearson[iMeasure, iDataset] <- cor(rawdata[,1], rawdata[, iMeasure + 1], use="complete.obs", method = "pearson")
table_Spearman[iMeasure, iDataset] <- cor(rawdata[,1], rawdata[, iMeasure + 1], use="complete.obs", method = "spearman")
table_Harmonic[iMeasure, iDataset] <- 2 * table_Pearson[iMeasure, iDataset] * table_Spearman[iMeasure, iDataset] / (table_Pearson[iMeasure, iDataset] + table_Spearman[iMeasure, iDataset])
}
}
# ------------------------------------------------------------
# We merge all metrics (Pearson, Spearman and Harmonic score)
# into a same data table by concatening previouos data tables.
# ------------------------------------------------------------
table_allMetrics <- cbind(table_Pearson, table_Spearman, table_Harmonic, Avg = rowMeans(table_Harmonic[1:nrow(table_Harmonic),]))
# table_allMetrics <- cbind(table_Pearson, table_Spearman, Avg = rowMeans(table_Harmonic[1:nrow(table_Harmonic),]))
table_allMetrics <- mat.sort(table_allMetrics, ncol(table_allMetrics), decreasing = TRUE)
# We set the column names to the final matrix
colnames(table_allMetrics) <- c("r", "r", "r",
'$\\rho$', '$\\rho$', '$\\rho$',
"h", "h", "h",
"Avg")
# colnames(table_allMetrics) <- c("r", "r", "r",
#                                 '$\\rho$', '$\\rho$', '$\\rho$',
#                                 "Avg")
# We reorder the matrix columns grouping by dataset names.
table_allMetrics <- table_allMetrics[ , c(1,4,7,2,5,8,3,6,9,10) ]
# table_allMetrics <- table_allMetrics[ , c(1,4,2,5,3,6,7) ]
# We make a copy of the tables in order to round their values to 3 decimal digits
table_allMetrics_rounded <- round(table_allMetrics, 3);
table_allMetrics_rounded <- as.data.frame(table_allMetrics_rounded)
table_allMetrics_rounded
# We save all final assembled data tables
write.csv(table_allMetrics, file = paste(outputDir,"table_allMetrics_", experimentLabel, ".csv", sep=""))
write.csv(table_allMetrics_rounded, file = paste(outputDir, "table_allMetrics_rounded_", experimentLabel, ".csv", sep=""))
# We add the output table to the Latex dictionary
latexTables$set(strCaption, table_allMetrics_rounded)
#-------------------------------
# LATEX report generation
#
# IMPORTANT NOTE: To avoid the problem of oversizing the box, add manually the next command BEFORE tabular:
#
# \resizebox{\columnwidth}{!}{%
#
# TABLE DATA
#
# }
# \end{table}
#-------------------------------
library(knitr)
library(readr)
library(kableExtra)
library(stringr)
library(xtable)
# We define the latex table with the data
table_latex <- xtable(table_allMetrics_rounded, type = "latex", digits=4, method = "compact")
# We add extra rows to the table before printing it
addtorow      <- list()
addtorow$pos  <- list()
# We add an extra header with the dataset groups
addtorow$pos[[1]] <- -1
addtorow$command  <- c('\\hline \\multicolumn{1}{c}{ } & \\multicolumn{3}{c}{BIOSSES} & \\multicolumn{3}{c}{MedSTS} & \\multicolumn{3}{c}{CTR} & \\multicolumn{1}{c}{Avg} \\\\ ')
tableLatex <- print(xtable(table_latex, caption = strCaption, digits=3), caption.placement = 'top',
add.to.row = addtorow, comment=FALSE, size="\\tiny", table.placement="!h", sanitize.colnames.function = identity)
# We save the tables in latex and HTML format files. The HTML format is for
strLatexTables <- paste(strLatexTables, sep="\n\n", tableLatex)
# Write the Latex table in a file
file_name <- paste(outputDir,"table_", experimentLabel, ".txt", sep="")
write_file(tableLatex, file_name)
# And open the table in the default file browser.
# browseURL(file_name)
}
# Write the Latex table in a file
file_name <- paste(outputDir,"table_allMetricsALLJoint.txt", sep="")
write_file(strLatexTables, file_name)
browseURL(file_name)
counter_executions
# Description:
#
# This script loads a collection of sentence similarity benchmarks generated
# by HESMLSTSclient program, which contain the raw similarity values for
# sentence pair. Then, the script computes a collection of consolidated tables
# including the Pearson, Spearman and harmonic score metrics.
#
# References:
# ----------
# We clear all session variables
rm(list = ls())
# IMPORTANT:configuration of the input/output directories
# We define below the input directory for the input raw results
# in CSV file format, and the output directory for the
# final assembled tables in CSV file format.
# You must change these values in order to
# point to the proper directories in your hard drive.
# We also define below the name of the input raw CSV files
# containing the experimental results.
# The input and output directories below must end with '/' in
# Unix-like format to be compatible with Windows
# or Linux-based R distributions.
# First, we get the current file script directory
current_working_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
# and we set the working directory for the R project
setwd(current_working_dir)
# Define the root path
rootDir = "../BioSentenceSimilarity_paper"
# We import the library that implements the data structures.
library(collections)
# We create an OrderedDict object with all the experiments that will be evaluated.
experiments <- ordered_dict()
# We define the subdirectory experiment and the caption for showing the results in Latex and HTML format
# and we add to the dictionary all the String-based measures experiments
experimentSubdirectory = "BioSentenceSimFinalRawOutputFiles"
preprocessedExperimentsSubdirectory = "BioSentenceSimFinalProcessedOutputFiles"
# We define the output directory
dir.create(paste(rootDir, "/", preprocessedExperimentsSubdirectory, "/", sep = ""))
outputDir =  paste(rootDir, "/", preprocessedExperimentsSubdirectory, "/", sep = "")
# Input raw CSV files generated by the reproducible experiments detailed
# in the companion paper for each sentence similarity dataset
# We define the input datasets directories
inputDir = paste(rootDir, "/", experimentSubdirectory, "/", sep = "")
# We load the input raw results file for best combinations (FINAL RESULTS)
source(paste("bio_sentence_sim_scripts", "readBESTCOMBS.R", sep = "/"), local = knitr::knit_global())
# We initialize the counter of executions
counter_executions <- 0
# We get the label
experimentLabel = rawdata_BESTCOMBS$label
# We get the experiment subdirectory and the caption for the Latex File
strCaption = paste("Table \\label{table:", experimentSubdirectory, "}: Pearson (r), Spearman ($\rho$) and Harmonic score (h) obtained by each unsupervised ", experimentLabel, " similarity method evaluated herein.", sep="")
rawdata_BIOSSES <- rawdata_BESTCOMBS$biosses
rawdata_MedSTS  <- rawdata_BESTCOMBS$medsts
rawdata_CTR     <- rawdata_BESTCOMBS$ctr
# mat.sort function is copied from source files of
# BioPhysConnectoR package which is now unavailable.
# Source code was retrieved from https://rdrr.io/cran/BioPhysConnectoR/src/R/mat.sort.r
mat.sort<-function(mat,sort,decreasing=FALSE)
{
m<-do.call("order",c(as.data.frame(mat[,sort]),decreasing=decreasing))
mat[m,]
}
# ---------------------------------------------------------------------
# Raw output file format:
# Raw similarity files contain the similarity values returned by each
# semantic measure for each sentence pair.
# First column contains the uman judgements for each sentence pair
# whilst subsequent columns contain the values returned by the
# sentence similaritu measures.
# ---------------------------------------------------------------------
# ---------------------------------------------------------------------
# Table 1: Pearson and Spearman metrics of all sentence similarity
# measures.
# ---------------------------------------------------------------------
# We split the MedSTS dataset into 10 subdataset to artificially increase the sample size
# from 3 datasets to 12 datasets.
# We calculate the total of rows per dataset
number_samples_per_subdataset <- nrow(rawdata_MedSTS) / 10
# We truncate the value
number_samples_per_subdataset_truncated <- trunc(number_samples_per_subdataset, 0)
# We split the dataset into 10 datasets of 106 rows (except for the last one, with XX rows)
init_value_split1 <- 1
end_value_split1 <- number_samples_per_subdataset_truncated
rawdata_MedSTS_split1 <- rawdata_MedSTS[init_value_split1:end_value_split1,]
init_value_split2 <- init_value_split1+number_samples_per_subdataset_truncated
end_value_split2 <- init_value_split2+number_samples_per_subdataset_truncated
rawdata_MedSTS_split2 <- rawdata_MedSTS[init_value_split2:end_value_split2,]
init_value_split3 <- init_value_split2+number_samples_per_subdataset_truncated+1
end_value_split3 <- init_value_split3+number_samples_per_subdataset_truncated
rawdata_MedSTS_split3 <- rawdata_MedSTS[init_value_split3:end_value_split3,]
init_value_split4 <- init_value_split3+number_samples_per_subdataset_truncated+1
end_value_split4 <- init_value_split4+number_samples_per_subdataset_truncated
rawdata_MedSTS_split4 <- rawdata_MedSTS[init_value_split4:end_value_split4,]
init_value_split5 <- init_value_split4+number_samples_per_subdataset_truncated+1
end_value_split5 <- init_value_split5+number_samples_per_subdataset_truncated
rawdata_MedSTS_split5 <- rawdata_MedSTS[init_value_split5:end_value_split5,]
init_value_split6 <- init_value_split5+number_samples_per_subdataset_truncated+1
end_value_split6 <- init_value_split6+number_samples_per_subdataset_truncated
rawdata_MedSTS_split6 <- rawdata_MedSTS[init_value_split6:end_value_split6,]
init_value_split7 <- init_value_split6+number_samples_per_subdataset_truncated+1
end_value_split7 <- init_value_split7+number_samples_per_subdataset_truncated
rawdata_MedSTS_split7 <- rawdata_MedSTS[init_value_split7:end_value_split7,]
init_value_split8 <- init_value_split7+number_samples_per_subdataset_truncated+1
end_value_split8 <- init_value_split8+number_samples_per_subdataset_truncated
rawdata_MedSTS_split8 <- rawdata_MedSTS[init_value_split8:end_value_split8,]
init_value_split9 <- init_value_split8+number_samples_per_subdataset_truncated+1
end_value_split9 <- init_value_split9+number_samples_per_subdataset_truncated
rawdata_MedSTS_split9 <- rawdata_MedSTS[init_value_split9:end_value_split9,]
# The last dataset has the remaining rows
init_value_split10 <- init_value_split9+number_samples_per_subdataset_truncated+1
end_value_split10 <- nrow(rawdata_MedSTS)
rawdata_MedSTS_split10 <- rawdata_MedSTS[init_value_split10:end_value_split10,]
# We define all datasets
# rawdata_allDatasets <- list(rawdata_BIOSSES, rawdata_MedSTS, rawdata_CTR)
rawdata_allDatasets <- list(rawdata_BIOSSES, rawdata_CTR, rawdata_MedSTS_split1,
rawdata_MedSTS_split2, rawdata_MedSTS_split3,
rawdata_MedSTS_split4, rawdata_MedSTS_split5,
rawdata_MedSTS_split6, rawdata_MedSTS_split7,
rawdata_MedSTS_split8, rawdata_MedSTS_split9,
rawdata_MedSTS_split10)
# We create a separated table for each metric by removing the first column
# which contains the human judgements. Measures are arranged in rows
# whilst datasets are arranged in columns.
table_Pearson <- matrix(nrow = ncol(rawdata_BIOSSES) - 1,
ncol = length(rawdata_allDatasets),
dimnames = list(colnames(rawdata_BIOSSES)[2:ncol(rawdata_BIOSSES)],
c("BIOSSES", "CTR",
"MedSTS_split1",
"MedSTS_split2",
"MedSTS_split3",
"MedSTS_split4",
"MedSTS_split5",
"MedSTS_split6",
"MedSTS_split7",
"MedSTS_split8",
"MedSTS_split9",
"MedSTS_split10")))
table_Spearman <- table_Pearson
table_Harmonic <- table_Pearson
# Loop for the computation of the metrics
nMeasures <- nrow(table_Pearson)
nDatasets <- length(rawdata_allDatasets)
for (iDataset in 1:nDatasets)
{
# We get the raw data of the next dataset
rawdata <- rawdata_allDatasets[[iDataset]]
# We evaluate the Pearson and Spearman metrics for each measure in the current dataset
for (iMeasure in 1:nMeasures)
{
table_Pearson[iMeasure, iDataset] <- cor(rawdata[,1], rawdata[, iMeasure + 1], use="complete.obs", method = "pearson")
table_Spearman[iMeasure, iDataset] <- cor(rawdata[,1], rawdata[, iMeasure + 1], use="complete.obs", method = "spearman")
table_Harmonic[iMeasure, iDataset] <- 2 * table_Pearson[iMeasure, iDataset] * table_Spearman[iMeasure, iDataset] / (table_Pearson[iMeasure, iDataset] + table_Spearman[iMeasure, iDataset])
}
}
# ------------------------------------------------------------
# We merge all metrics (Pearson, Spearman and Harmonic score)
# into a same data table by concatening previouos data tables.
# ------------------------------------------------------------
table_allMetrics <- cbind(table_Pearson, table_Spearman, table_Harmonic, Avg = rowMeans(table_Harmonic[1:nrow(table_Harmonic),]))
# table_allMetrics <- cbind(table_Pearson, table_Spearman, Avg = rowMeans(table_Harmonic[1:nrow(table_Harmonic),]))
table_allMetrics <- mat.sort(table_allMetrics, ncol(table_allMetrics), decreasing = TRUE)
ncol(table_allMetrics)
# We set the column names to the final matrix
colnames(table_allMetrics) <- c("r", "r", "r", "r", "r", "r", "r", "r", "r", "r", "r", "r",
'$\\rho$', '$\\rho$', '$\\rho$', '$\\rho$', '$\\rho$', '$\\rho$', '$\\rho$', '$\\rho$', '$\\rho$', '$\\rho$', '$\\rho$', '$\\rho$',
"h", "h", "h", "h", "h", "h", "h", "h", "h", "h", "h", "h",
"Avg")
# We reorder the matrix columns grouping by dataset names.
# table_allMetrics <- table_allMetrics[ , c(1,4,7,2,5,8,3,6,9,10) ]
# This script computes a matrix of pairwise p-values between
# a set of methods defined by row vectors.
# We read the raw table generated by HESMLSTSclient
# and compute the p-values
# We get the dimensions of the matrix using the harmonic values
rowBasedMatrixMethods <- table_allMetrics[,25:36]
rowNames <- rownames(table_allMetrics)
# We get the dimensions of the matrix
nrows = nrow(rowBasedMatrixMethods)
ncols = ncol(rowBasedMatrixMethods)
# We create a blank square matrix to store the pairwise
outputMatrix = matrix(nrow=nrows,ncol=nrows)
# We compute the p-values between pairwise methods
for (i in 1:(nrows - 1))
{
for (j in (i + 1):nrows)
{
val <- as.numeric(matrix(rowBasedMatrixMethods[i,1:ncols]))
val
outputMatrix[i,j] = t.test(x = as.numeric(matrix(rowBasedMatrixMethods[i,1:ncols])),
y = as.numeric(matrix(rowBasedMatrixMethods[j,1:ncols])), alternative = "greater",
mu = 0, paired = TRUE, conf.level = 0.95)$p.value * 0.5
outputMatrix[j,i] = outputMatrix[i,j]
}
}
# We set the names of rows and columns
colnames(outputMatrix) = rowNames
rownames(outputMatrix) = rowNames
final_data <- round(outputMatrix, 3)
final_data
write.csv(final_data, file = paste(outputDir, sep="","Pvalues.csv"))
